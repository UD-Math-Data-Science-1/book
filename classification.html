<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.339">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science 1 - 3&nbsp; Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./selection.html" rel="next">
<link href="./stats.html" rel="prev">
<link href="./_media/logo_small.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<script> 
MathJax = {
  chtml: {
    scale: 0.92,
  }
}
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./classification.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Classification</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="quarto-sidebar-header"><div class="sidebar-header-item">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="_media/logo_small.png" height="120" class="figure-img"></p>
</figure>
</div>
</div></div>
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science 1</a> 
        <div class="sidebar-tools-main">
    <a href="./Data-Science-1.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">List of examples</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Resources</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./starting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting started</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genAI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generative AI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Representation of data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Descriptive statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Model selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Networks</span></span></a>
  </div>
</li>
    </ul>
    </div>
<div class="quarto-sidebar-footer"><div class="sidebar-footer-item">
<p>Copyright (c) 2024 by <a href="https://tobydriscoll.net">Toby Driscoll</a></p>
</div></div></nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#classification-basics" id="toc-classification-basics" class="nav-link active" data-scroll-target="#classification-basics"><span class="header-section-number">3.1</span> Classification basics</a>
  <ul class="collapse">
  <li><a href="#encoding-qualitative-data" id="toc-encoding-qualitative-data" class="nav-link" data-scroll-target="#encoding-qualitative-data"><span class="header-section-number">3.1.1</span> Encoding qualitative data</a></li>
  <li><a href="#walkthrough" id="toc-walkthrough" class="nav-link" data-scroll-target="#walkthrough"><span class="header-section-number">3.1.2</span> Walkthrough</a></li>
  </ul></li>
  <li><a href="#classifier-performance" id="toc-classifier-performance" class="nav-link" data-scroll-target="#classifier-performance"><span class="header-section-number">3.2</span> Classifier performance</a>
  <ul class="collapse">
  <li><a href="#traintest-paradigm" id="toc-traintest-paradigm" class="nav-link" data-scroll-target="#traintest-paradigm"><span class="header-section-number">3.2.1</span> Train–test paradigm</a></li>
  <li><a href="#binary-classifiers" id="toc-binary-classifiers" class="nav-link" data-scroll-target="#binary-classifiers"><span class="header-section-number">3.2.2</span> Binary classifiers</a></li>
  <li><a href="#multiclass-classifiers" id="toc-multiclass-classifiers" class="nav-link" data-scroll-target="#multiclass-classifiers"><span class="header-section-number">3.2.3</span> Multiclass classifiers</a></li>
  </ul></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees"><span class="header-section-number">3.3</span> Decision trees</a>
  <ul class="collapse">
  <li><a href="#gini-impurity" id="toc-gini-impurity" class="nav-link" data-scroll-target="#gini-impurity"><span class="header-section-number">3.3.1</span> Gini impurity</a></li>
  <li><a href="#partitioning" id="toc-partitioning" class="nav-link" data-scroll-target="#partitioning"><span class="header-section-number">3.3.2</span> Partitioning</a></li>
  <li><a href="#decision-boundary" id="toc-decision-boundary" class="nav-link" data-scroll-target="#decision-boundary"><span class="header-section-number">3.3.3</span> Decision boundary</a></li>
  <li><a href="#usage-and-interpretation" id="toc-usage-and-interpretation" class="nav-link" data-scroll-target="#usage-and-interpretation"><span class="header-section-number">3.3.4</span> Usage and interpretation</a></li>
  </ul></li>
  <li><a href="#nearest-neighbors" id="toc-nearest-neighbors" class="nav-link" data-scroll-target="#nearest-neighbors"><span class="header-section-number">3.4</span> Nearest neighbors</a>
  <ul class="collapse">
  <li><a href="#distances-and-norms" id="toc-distances-and-norms" class="nav-link" data-scroll-target="#distances-and-norms"><span class="header-section-number">3.4.1</span> Distances and norms</a></li>
  <li><a href="#algorithm" id="toc-algorithm" class="nav-link" data-scroll-target="#algorithm"><span class="header-section-number">3.4.2</span> Algorithm</a></li>
  <li><a href="#standardization" id="toc-standardization" class="nav-link" data-scroll-target="#standardization"><span class="header-section-number">3.4.3</span> Standardization</a></li>
  </ul></li>
  <li><a href="#sec-class-probabilistic" id="toc-sec-class-probabilistic" class="nav-link" data-scroll-target="#sec-class-probabilistic"><span class="header-section-number">3.5</span> Probabilistic interpretation</a>
  <ul class="collapse">
  <li><a href="#roc-curve" id="toc-roc-curve" class="nav-link" data-scroll-target="#roc-curve"><span class="header-section-number">3.5.1</span> ROC curve</a></li>
  <li><a href="#auc" id="toc-auc" class="nav-link" data-scroll-target="#auc"><span class="header-section-number">3.5.2</span> AUC</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Classification</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>

<div class="hidden">
<p><span class="math display">\[
    \newcommand{\float}{\mathbb{F}}
    \newcommand{\real}{\mathbb{R}}
    \newcommand{\complex}{\mathbb{C}}
    \newcommand{\nat}{\mathbb{N}}
    \newcommand{\integer}{\mathbb{Z}}
    \newcommand{\bfa}{\mathbf{a}}
    \newcommand{\bfe}{\mathbf{e}}
    \newcommand{\bfh}{\mathbf{h}}
    \newcommand{\bfp}{\mathbf{p}}
    \newcommand{\bfq}{\mathbf{q}}
    \newcommand{\bfu}{\mathbf{u}}
    \newcommand{\bfv}{\mathbf{v}}
    \newcommand{\bfw}{\mathbf{w}}
    \newcommand{\bfx}{\mathbf{x}}
    \newcommand{\bfy}{\mathbf{y}}
    \newcommand{\bfz}{\mathbf{z}}
    \newcommand{\bfA}{\mathbf{A}}
    \newcommand{\bfW}{\mathbf{W}}
    \newcommand{\bfX}{\mathbf{X}}
    \newcommand{\bfzero}{\boldsymbol{0}}
    \newcommand{\bfmu}{\boldsymbol{\mu}}
    \newcommand{\TP}{\text{TP}}
    \newcommand{\TN}{\text{TN}}
    \newcommand{\FP}{\text{FP}}
    \newcommand{\FN}{\text{FN}}
    \newcommand{\rmn}[2]{\mathbb{R}^{#1 \times #2}}
    \newcommand{\dd}[2]{\frac{d #1}{d #2}}
    \newcommand{\pp}[2]{\frac{\partial #1}{\partial #2}}
    \newcommand{\norm}[1]{\left\lVert \mathstrut #1 \right\rVert}
    \newcommand{\abs}[1]{\left\lvert \mathstrut #1 \right\rvert}
    \newcommand{\twonorm}[1]{\norm{#1}_2}
    \newcommand{\onenorm}[1]{\norm{#1}_1}
    \newcommand{\infnorm}[1]{\norm{#1}_\infty}
    \newcommand{\innerprod}[2]{\langle #1,#2 \rangle}
    \newcommand{\pr}[1]{^{(#1)}}
    \newcommand{\diag}{\operatorname{diag}}
    \newcommand{\sign}{\operatorname{sign}}
    \newcommand{\dist}{\operatorname{dist}}
    \newcommand{\simil}{\operatorname{sim}}
    \newcommand{\ee}{\times 10^}
    \newcommand{\floor}[1]{\lfloor#1\rfloor}
    \newcommand{\argmin}{\operatorname{argmin}}
    \newcommand{\E}[1]{\operatorname{\mathbb{E}}\left[\mathstrut #1\right]}
    \newcommand{\Cov}{\operatorname{Cov}}
    \newcommand{\logit}{\operatorname{logit}}
\]</span></p>
</div>
<p>Machine learning is the use of data to tune algorithms for making decisions or predictions. Unlike deduction based on reasoning from principles governing the application, machine learning is a “black box” that just adapts via training.</p>
<p>We divide machine learning into three major forms:</p>
<dl>
<dt>Supervised learning</dt>
<dd>
The training data only examples that include the answer (or <strong>label</strong>) we expect to get. The goals are to find important effects and/or to predict labels for previously unseen examples.
</dd>
<dt>Unsupervised learning</dt>
<dd>
The data is unlabeled, and the goal is to discover structure and relationships inherent to the data set.
</dd>
<dt>Reinforcement learning</dt>
<dd>
The data is unlabeled, but there are known rules and goals that can be encouraged through penalties and rewards.
</dd>
</dl>
<p>We start with supervised learning, which can be subdivided into two major areas:</p>
<ul>
<li><strong>Classification</strong>, in which the algorithm is expected to choose from among a finite set of options.</li>
<li><strong>Regression</strong>, in which the algorithm should predict the value of a quantitative variable.</li>
</ul>
<p>Most algorithms for one of these problems have counterparts in the other.</p>
<section id="classification-basics" class="level2 page-columns page-full" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="classification-basics"><span class="header-section-number">3.1</span> Classification basics</h2>
<p>A single training example or sample is characterized by a <strong>feature vector</strong> <span class="math inline">\(\bfx\)</span> of <span class="math inline">\(d\)</span> real numbers and a <strong>label</strong> <span class="math inline">\(y\)</span> drawn from a finite set <span class="math inline">\(L\)</span>. If <span class="math inline">\(L\)</span> has only two members (say, “true” and “false”), we have a <strong>binary classification</strong> problem; otherwise, we have a <strong>multiclass</strong> problem.</p>
<p>When we have <span class="math inline">\(n\)</span> training samples, it’s natural to collect them into columns of a <strong>feature matrix</strong> <span class="math inline">\(\bfX\)</span> with <span class="math inline">\(n\)</span> rows and <span class="math inline">\(d\)</span> columns. Using subscripts to represent the indexes of the matrix, we can write</p>
<p><span class="math display">\[
\bfX = \begin{bmatrix}
X_{11} &amp; X_{12} &amp; \cdots &amp; X_{1d} \\
X_{21} &amp; X_{22} &amp; \cdots &amp; X_{2d} \\
\vdots &amp; \vdots &amp;&amp; \vdots \\
X_{n1} &amp; X_{n2} &amp; \cdots &amp; X_{nd}
\end{bmatrix}.
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_k80zm74i&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_waoitbmv" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.1" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>A 2D array or matrix has elements that are addressed by two subscripts. These are always given in order <em>row</em>, <em>column</em>.</p>
<p>In math, we usually start the row and column indexes at 1, but Python starts them at 0.</p>
</div>
</div>
<p>Each row of the feature matrix is a single feature vector, while each column is the value for a single feature over the entire training set.</p>
<div id="exm-class-basketball" class="theorem example" data-chapter="3" type="✍️" data-description="Feature matrix">
<p><span class="theorem-title"><strong>Example 3.1 </strong></span>Suppose we want to train an algorithm to predict whether a basketball shot will score. For one shot, we might collect three coordinates to represent the launch point, three to represent the launch velocity, and three to represent the initial angular rotation (axis and magnitude). Thus each shot will require a feature vector of length 9. A collection of 200 sample shots would be encoded as a <span class="math inline">\(200\times 9\)</span> feature matrix.</p>
</div>
<p>We can also collect the associated training labels into the <strong>label vector</strong></p>
<p><span class="math display">\[
\bfy = \begin{bmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{bmatrix}
\]</span></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In linear algebra, the default shape for a vector is usually as a single column. In Python, a vector doesn’t exactly have a row or column orientation, though when it matters, a row shape is usually preferred.</p>
</div>
</div>
<p>Each component <span class="math inline">\(y_i\)</span> of the label vector is drawn from the label set <span class="math inline">\(L\)</span>.</p>
<!-- ### One-vs-rest

Many classification algorithms are derived for binary classification problems, in which there are only two unique labels. There are automatic ways of upgrading this capability to a multiclass problem. Probably the most useful one is the **one versus rest** or *one versus all* method. 

Suppose the label set $L$ has $m > 2$ members, which we can arbitrarily denote by the integers $1$ through $m$. We can define $m$ separate binary classification problems with the true/false label sets
$$
L_k = \{ y=k, y\neq k\},
$$
for each $k=1,2,\ldots,m$.  -->
<section id="encoding-qualitative-data" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="encoding-qualitative-data"><span class="header-section-number">3.1.1</span> Encoding qualitative data</h3>
<p>We have defined the features as numerical values. What should we do with qualitative data? We could arbitrarily assign numbers to possible values, such as “0=red”, “1=blue”, “2=yellow,” and so on. But this is not ideal: most of the time, we would not want to say that yellow is twice as far from red as it is from blue!</p>
<p>A better strategy is to use the one-hot or dummy encoding. If a particular feature can take on <span class="math inline">\(k\)</span> unique values, then we introduce <span class="math inline">\(k\)</span> new features indicating which value is present. (We can use <span class="math inline">\(k-1\)</span> dummy features if we interpret all-zeros to mean the <span class="math inline">\(k\)</span>th possibility.)</p>
</section>
<section id="walkthrough" class="level3 page-columns page-full" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="walkthrough"><span class="header-section-number">3.1.2</span> Walkthrough</h3>
<p>The <em>scikit-learn</em> package <code>sklearn</code> is a collection of well-known machine learning algorithms and tools. Scikit-learn offers a uniform framework across all classifier types:</p>
<ol type="1">
<li>Define features and labels as numpy arrays or pandas frames.</li>
<li>Create a learner object, specifying any values that specialize the behavior.</li>
<li>Train the learner on the data by calling the <code>fit</code> method.</li>
<li>Apply the learner to a feature matrix/frame using the <code>predict</code> method.</li>
</ol>
<p>The package also includes a few classic example datasets. We load one derived from automatic recognition of handwritten digits:</p>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_f63ccqhd&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_kw47k6ng" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.1.2" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div id="087c6267" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> datasets.load_digits()        <span class="co"># loads a well-known dataset</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>X, digits <span class="op">=</span> ds[<span class="st">"data"</span>], ds[<span class="st">"target"</span>]      <span class="co"># assign feature matrix and label vector</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The feature matrix has shape"</span>, X.shape)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The label vector has shape"</span>, digits.shape)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>n, d <span class="op">=</span> X.shape</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"there are"</span>, d, <span class="st">"features and"</span>, n, <span class="st">"samples"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The feature matrix has shape (1797, 64)
The label vector has shape (1797,)
there are 64 features and 1797 samples</code></pre>
</div>
</div>
<p>The entries of <code>digits</code> are integer values 0 through 9, indicating the true value of the corresponding handwritten digit. Let’s consider the binary problem, “is this digit a 6?” That implies the following Boolean label vector:</p>
<div id="753b524d" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (digits <span class="op">==</span> <span class="dv">6</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of sixes in dataset:"</span>, <span class="bu">sum</span>(y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of sixes in dataset: 181</code></pre>
</div>
</div>
<p>It so happens that the 64 features in the dataset are the pixel grayscale values from an <span class="math inline">\(8\times 8\)</span> bitmap of a handwritten digit. We can visualize the raw data. Here are some of the 6s, for example:</p>
<div id="f7896019" class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_digits(X):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>,<span class="dv">4</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>            row <span class="op">=</span> j <span class="op">+</span> <span class="dv">4</span><span class="op">*</span>i</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>            A <span class="op">=</span> np.reshape(np.array(X[row,:]),(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>            sns.heatmap(A,ax<span class="op">=</span>axes[i,j],square<span class="op">=</span><span class="va">True</span>,cmap<span class="op">=</span><span class="st">"gray"</span>,cbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            axes[i,j].axis(<span class="va">False</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plot_digits(X[y])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-4-output-1.png" width="507" height="389"></p>
</div>
</div>
<p>The process of training a classifier is called <strong>fitting</strong>. We first have to import a particular classifier type, then create an instance of that type. Here, we choose one that we will study in a future section:</p>
<div id="7020d599" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">20</span>)    <span class="co"># specification of the model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can fit the learner to the training data:</p>
<div id="afe3a986" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>knn.fit(X, y)                                 <span class="co"># training of the model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier(n_neighbors=20)</pre></div></div></div></div></div>
</div>
</div>
<p>At this point, the classifier object <code>knn</code> has figured out what it needs from the training data. It has methods we can now call to make predictions and evaluate the quality of the results.</p>
<p>Each new prediction is for a <strong>query vector</strong> with 64 features. In practice, we can use a list in place of a vector for the query.</p>
<div id="c48f7c91" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> [<span class="dv">20</span>]<span class="op">*</span>d    <span class="co"># list with d copies of 20  </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>predict</code> method of the classifier allows specifying multiple query vectors as rows of an array. In fact, it expects a 2D array in all cases, even if there is just one row.</p>
<div id="767e62c0" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>Xq <span class="op">=</span> [ query ]    <span class="co"># 2D array with a single row</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The result of the prediction will be a vector of labels, one per row of the query.</p>
<div id="22716c78" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get vector of predictions:</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>knn.predict(Xq)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>array([False])</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>predict</code> method requires a vector or list of query vectors or lists and it outputs a vector of classes. This is true even if there is just a single query.</p>
</div>
</div>
<p>At the moment, we don’t have any realistic query data at hand other than the training data. But we can investigate the question of how well the classifier does on that data, simply by using the feature matrix as the query:</p>
<div id="36893d3a" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get vector of predictions for the training set:</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> knn.predict(X)    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we simply count up the number of correctly predicted labels and divide by the total number of samples to get the <strong>accuracy</strong> of the classifier.</p>
<div id="8d08a46f" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> <span class="bu">sum</span>(yhat <span class="op">==</span> y) <span class="op">/</span> n    <span class="co"># fraction of correct predictions</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"accuracy is </span><span class="sc">{</span>acc<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>accuracy is 99.9%</code></pre>
</div>
</div>
<p>Not surprisingly, sklearn has functions for doing this measurement in fewer steps. The <code>metrics</code> module has functions that can compare true labels with predictions. In addition, each classifier object has a <code>score</code> method that allows you to skip finding the predictions vector yourself.</p>
<div id="01d6b5f2" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare original labels to predictions:</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> accuracy_score(y, yhat)    </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"accuracy score is </span><span class="sc">{</span>acc<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Same result, if we don't want to keep the predicted values around:</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> knn.score(X, y)    </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"knn score is </span><span class="sc">{</span>acc<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>accuracy score is 99.9%
knn score is 99.9%</code></pre>
</div>
</div>
<p>Does this mean that the classifier is a good one? The raw number looks great, but that question is more subtle than you would expect.</p>
<!-- ![](_media/memes/biden.png){height="240"} -->
</section>
</section>
<section id="classifier-performance" class="level2 page-columns page-full" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="classifier-performance"><span class="header-section-number">3.2</span> Classifier performance</h2>
<p>Let’s return to the (previously cleaned) loan applications dataset.</p>
<div id="a31903b4" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>loans <span class="op">=</span> pd.read_csv(<span class="st">"_datasets/loan_clean.csv"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>loans.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">loan_amnt</th>
<th data-quarto-table-cell-role="th">int_rate</th>
<th data-quarto-table-cell-role="th">installment</th>
<th data-quarto-table-cell-role="th">annual_inc</th>
<th data-quarto-table-cell-role="th">dti</th>
<th data-quarto-table-cell-role="th">delinq_2yrs</th>
<th data-quarto-table-cell-role="th">delinq_amnt</th>
<th data-quarto-table-cell-role="th">percent_funded</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5000</td>
<td>10.65</td>
<td>162.87</td>
<td>24000.0</td>
<td>27.65</td>
<td>0</td>
<td>0</td>
<td>100.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2500</td>
<td>15.27</td>
<td>59.83</td>
<td>30000.0</td>
<td>1.00</td>
<td>0</td>
<td>0</td>
<td>100.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2400</td>
<td>15.96</td>
<td>84.33</td>
<td>12252.0</td>
<td>8.72</td>
<td>0</td>
<td>0</td>
<td>100.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>10000</td>
<td>13.49</td>
<td>339.31</td>
<td>49200.0</td>
<td>20.00</td>
<td>0</td>
<td>0</td>
<td>100.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>3000</td>
<td>12.69</td>
<td>67.79</td>
<td>80000.0</td>
<td>17.94</td>
<td>0</td>
<td>0</td>
<td>100.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We create a binary classification problem by labelling whether each loan was at least 95% funded. The other columns will form the features for the predictions.</p>
<div id="a702a821" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> loans.drop(<span class="st">"percent_funded"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> loans[<span class="st">"percent_funded"</span>] <span class="op">&gt;</span> <span class="dv">95</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_x9ekm6vr&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_94rtn1p9" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.2" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><section id="traintest-paradigm" class="level3 page-columns page-full" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="traintest-paradigm"><span class="header-section-number">3.2.1</span> Train–test paradigm</h3>
<p>It seems desirable for a classifier to work well on the samples it was trained on. But we probably want to do more than that.</p>
<div id="def-class-generalization" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1 </strong></span>The performance of a predictor on previously unseen data is known as the <strong>generalization</strong> of the predictor.</p>
</div>
<p>In order to gauge generalization, we hold back some of the labeled data from training and use it only to test the performance. An <code>sklearn</code> helper function called <code>train_test_split</code> allows us to split off 20% of the data to use for testing. It’s usually recommended to shuffle the order of the samples before the split, and in order to make the results reproducible, we give a specific random seed to the RNG used for the shuffle.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_6o101qr3&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_rk4sf8p4" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.2.1" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div id="d60f86bd" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  test_size<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  random_state<span class="op">=</span><span class="dv">3</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are"</span>, X_train.shape[<span class="dv">0</span>], <span class="st">"training samples."</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are"</span>, X_test.shape[<span class="dv">0</span>], <span class="st">"testing samples."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>There are 31773 training samples.
There are 7944 testing samples.</code></pre>
</div>
</div>
<p>We can check that the test and train labels have similar characteristics:</p>
<div id="41fd890c" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"labels in the training set:"</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( pd.Series(y_train).describe() )</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">labels in the testing set:"</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( pd.Series(y_test).describe() )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>labels in the training set:
count     31773
unique        2
top        True
freq      30351
Name: percent_funded, dtype: object

labels in the testing set:
count     7944
unique       2
top       True
freq      7575
Name: percent_funded, dtype: object</code></pre>
</div>
</div>
<p>Now we train on the training data…</p>
<div id="5298c608" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)    <span class="co"># fit only to train set</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier(n_neighbors=9)</pre></div></div></div></div></div>
</div>
</div>
<p>…and test on the rest.</p>
<div id="40e11bdc" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> knn.score(X_test, y_test)    <span class="co"># score only on test set</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"test accuracy is </span><span class="sc">{</span>acc<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>test accuracy is 95.6%</code></pre>
</div>
</div>
<p>This seems like a high accuracy, perhaps. But consider that the vast majority of loans were funded:</p>
<div id="fefb19f6" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>funded <span class="op">=</span> <span class="bu">sum</span>(y)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>funded<span class="op">/</span><span class="bu">len</span>(y)<span class="sc">:.1%}</span><span class="ss"> were funded"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>95.5% were funded</code></pre>
</div>
</div>
<p>Therefore, an algorithm that simply “predicts” funding every single loan could do as well as the trained classifier!</p>
<div id="3ed49941" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>generous <span class="op">=</span> [<span class="va">True</span>]<span class="op">*</span><span class="bu">len</span>(y_test)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> accuracy_score(y_test, generous)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"fund-them-all accuracy is </span><span class="sc">{</span>acc<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>fund-them-all accuracy is 95.4%</code></pre>
</div>
</div>
<p>In this context, our trained classifier is not impressive at all. We need a metric other than accuracy.</p>
</section>
<section id="binary-classifiers" class="level3 page-columns page-full" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="binary-classifiers"><span class="header-section-number">3.2.2</span> Binary classifiers</h3>
<p>A binary classifier is one that produces just two unique labels, which we call “yes” and “no” here. To fully understand the performance of a binary classifier, we have to account for four cases:</p>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_m5keewod&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_2971rmo5" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.2.2" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><ul>
<li>True positives (TP): Predicts “yes”, actually is “yes”</li>
<li>False positives (FP): Predicts “yes”, actually is “no”</li>
<li>True negatives (TN): Predicts “no”, actually is “no”</li>
<li>False negatives (FN): Predicts “no”, actually is “yes”</li>
</ul>
<p>We often display these in a 2×2 table according to the states of the prediction and <em>ground truth</em> (i.e., the given label in the dataset). The table can be filled with counts or percentages of tested instances to create a <strong>confusion matrix</strong>, as illustrated in <a href="#fig-class-confusion" class="quarto-xref">Figure&nbsp;<span>3.1</span></a>.</p>
<div id="fig-class-confusion" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="_media/confusion.png" alt="A binary confusion matrix." height="240" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3.1: A confusion matrix. Correct predictions are on the diagonal.</figcaption>
</figure>
</div>
<div id="def-class-metrics" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.2 </strong></span>The following primary metrics are defined for a binary classifier:</p>
<table class="table">
<colgroup>
<col style="width: 45%">
<col style="width: 54%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: right;"><strong>accuracy</strong></td>
<td style="text-align: center;"><span class="math inline">\(\dfrac{\TP + \TN}{\TP + \FP + \TN + \FN}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: right;"><strong>recall</strong></td>
<td style="text-align: center;"><span class="math inline">\(\dfrac{\TP}{\TP + \FN}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>specificity</strong></td>
<td style="text-align: center;"><span class="math inline">\(\dfrac{\TN}{\TN + \FP}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: right;"><strong>precision</strong></td>
<td style="text-align: center;"><span class="math inline">\(\dfrac{\TP}{\TP + \FP}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>negative predictive value</strong> (NPV)</td>
<td style="text-align: center;"><span class="math inline">\(\dfrac{\TN}{\TN + \FN}\)</span></td>
</tr>
</tbody>
</table>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recall is also known as <em>sensitivity</em> or the <em>true positive rate</em>. Specificity is the <em>true negative rate</em>.</p>
</div>
</div>
<p>All of the primary metrics vary between 0 (worst) and 1 (best). Accuracy is self-explanatory; the other metrics answer the following questions:</p>
<ul>
<li><strong>recall</strong> How often are actual “yes” cases predicted correctly?</li>
<li><strong>specificity</strong> How often are actual “no” cases predicted correctly?</li>
<li><strong>precision</strong> How often are the “yes” predictions correct?</li>
<li><strong>NPV</strong> How often are the “no” predictions correct?</li>
</ul>
<div id="exm-class-confusion" class="theorem example" data-chapter="3" type="✍️" data-description="Classifier performance metrics">
<p><span class="theorem-title"><strong>Example 3.2 </strong></span>Here is a confusion matrix for a hypothetical test for COVID-19 antigens applied to 100 samples:</p>
<table class="table">
<tbody>
<tr class="odd">
<td style="text-align: right;"></td>
<td style="text-align: center;">Predicted <span class="math inline">\(+\)</span></td>
<td style="text-align: center;">Predicted <span class="math inline">\(-\)</span></td>
</tr>
<tr class="even">
<td style="text-align: right;">Actually <span class="math inline">\(+\)</span></td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Actually <span class="math inline">\(-\)</span></td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">62</td>
</tr>
</tbody>
</table>
<p>From this we see that the accuracy is <span class="math inline">\(84/100\)</span>, or 84%. Out of 26 samples that had the antigen, the test identified 22, for a recall of <span class="math inline">\(22/26=84.6\)</span>%. Out of 74 samples that did not have the antigen, 62 were predicted correctly, for a specificity of <span class="math inline">\(62/74=83.8\)</span>%. Finally, the precision is <span class="math inline">\(22/34=64.7\)</span>% and the NPV is <span class="math inline">\(62/66=93.9\)</span>%.</p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:400px">
<div style="position:relative;padding-bottom:71.25%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_uz0psivl&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_0fv0iriz" width="400" height="285" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.2" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0">
</iframe>
</div>
</div>
</div></div><p>The metrics to pay attention to depend on the context and application. For a pregnancy test, for example, the health consequences of a false negative might be substantial, so the manufacturer might aim mainly for a high recall rate. But a risk-averse loan officer would be most concerned about making loans to those who end up defaulting, i.e.&nbsp;a low false positive rate, and seek a high precision.</p>
<p>There are ways of combining the primary metrics in order to account for two at once.</p>
<div id="def-class-metrics-2nd" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.3 </strong></span>The <strong><em>F</em>₁ score</strong> is the harmonic mean of the precision and the recall, i.e., <span class="math display">\[
F_1 = \left[ \frac{1}{2} \left(\frac{1}{\text{precision}} + \frac{1}{\text{recall}} \right)  \right]^{-1} = \frac{2\TP}{2\TP+\FN+\FP}.
\]</span></p>
<p>The <strong>balanced accuracy</strong> is the arithmetic mean of recall and specificity.</p>
</div>
<p>Like the primary metrics, <span class="math inline">\(F_1\)</span> and balanced accuracy range between 0 (worst) and 1 (best). The harmonic mean is small if either of its terms is small, so a high <span class="math inline">\(F_1\)</span> means both precision and recall are good.</p>
<div id="exm-class-metrics" class="theorem example" data-chapter="3" type="💻" data-description="Binary classifier metrics">
<p><span class="theorem-title"><strong>Example 3.3 </strong></span>Continuing with the loan classifier trained earlier in this section, we can find the confusion matrix:</p>
<div id="2b36f02f" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> confusion_matrix(y_test, yhat, labels<span class="op">=</span>[<span class="va">True</span>, <span class="va">False</span>])</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>C</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>array([[7570,    5],
       [ 343,   26]])</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>It’s advisable to always call <code>confusion_matrix</code> with the <code>labels</code> argument, even though it is optional, in order to control the ordering within the matrix. In particular, <code>False</code> &lt; <code>True</code>, so the default for Boolean labels is to count the upper left corner of the matrix as “true negatives,” assuming that <code>False</code> represents a negative result.</p>
</div>
</div>
<p>In order order to help keep track of what the entries mean, we can also make a picture of the confusion matrix:</p>
<div id="c141f6a0" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>lbl <span class="op">=</span> [<span class="st">"fund"</span>, <span class="st">"reject"</span>]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay(C, display_labels<span class="op">=</span>lbl).plot()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-22-output-1.png" width="542" height="429"></p>
</div>
</div>
<p>Hence, there are 7570 true positives. The accuracy is</p>
<div id="da570e0d" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f"accuracy = </span><span class="sc">{</span>(<span class="dv">7570</span> <span class="op">+</span> <span class="dv">26</span>) <span class="op">/</span> np<span class="sc">.</span><span class="bu">sum</span>(C)<span class="sc">:.1%}</span><span class="ss">"</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>accuracy = 95.6%</code></pre>
</div>
</div>
<p>(In practice, of course, we can use the <code>accuracy</code> function we imported earlier.) Here are the other primary scores:</p>
<div id="a0a42d02" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>TP, FN, FP, TN <span class="op">=</span> C.ravel()    <span class="co"># grab the 4 values in the confusion matrix</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f"recall = </span><span class="sc">{</span>TP<span class="op">/</span>(TP<span class="op">+</span>FN)<span class="sc">:.1%}</span><span class="ss">"</span> )</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f"specificity = </span><span class="sc">{</span>TN<span class="op">/</span>(TN<span class="op">+</span>FP)<span class="sc">:.1%}</span><span class="ss">"</span> )</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f"precision = </span><span class="sc">{</span>TP<span class="op">/</span>(TP<span class="op">+</span>FP)<span class="sc">:.1%}</span><span class="ss">"</span> )</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f"NPV = </span><span class="sc">{</span>TN<span class="op">/</span>(TN<span class="op">+</span>FN)<span class="sc">:.1%}</span><span class="ss">"</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>recall = 99.9%
specificity = 7.0%
precision = 95.7%
NPV = 83.9%</code></pre>
</div>
</div>
<p>As noted above, few who ought to get a loan will go away disappointed, a loan officer might get nervous about the low specificity score that indicates bad loans.</p>
<p>In <code>sklearn.metrics</code> there are functions to compute recall and precision without reference to the confusion matrix. You must put the ground-truth labels before the predicted labels, and you should also specify which label value corresponds to a “positive” result. Swapping the “positive” role effectively swaps recall with specificity and precision with NPV.</p>
<div id="fabd58c6" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> pos <span class="kw">in</span> [<span class="va">True</span>, <span class="va">False</span>]:</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"With"</span>, pos, <span class="st">"as positive:"</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  s <span class="op">=</span> recall_score(y_test, yhat, pos_label<span class="op">=</span>pos)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"    recall is </span><span class="sc">{</span>s<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  s <span class="op">=</span> precision_score(y_test, yhat, pos_label<span class="op">=</span>pos) </span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"    precision is </span><span class="sc">{</span>s<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>With True as positive:
    recall is 0.999
    precision is 0.957

With False as positive:
    recall is 0.070
    precision is 0.839
</code></pre>
</div>
</div>
<p>There are also functions for the composite scores defined in <a href="#def-class-metrics-2nd" class="quarto-xref">Definition&nbsp;<span>3.3</span></a>:</p>
<div id="22df9bef" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score, balanced_accuracy_score</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f"F1 = </span><span class="sc">{</span>f1_score(y_test, yhat)<span class="sc">:.1%}</span><span class="ss">"</span> )</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f"balanced accuracy = </span><span class="sc">{</span>balanced_accuracy_score(y_test, yhat)<span class="sc">:.1%}</span><span class="ss">"</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F1 = 97.8%
balanced accuracy = 53.5%</code></pre>
</div>
</div>
<p>The loan classifier has excellent recall, respectable precision, and terrible specificity, resulting in a good <em>F</em>₁ score and a low balanced accuracy score.</p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_d1ye0bph&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_96mrc7cd" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.3" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div id="exm-class-scores-simple" class="theorem example" data-chapter="3" type="✍️" data-description="Combined metrics">
<p><span class="theorem-title"><strong>Example 3.4 </strong></span>If <span class="math inline">\(k\)</span> of the <span class="math inline">\(n\)</span> testing samples were funded loans, then the fund-them-all loan classifier has</p>
<p><span class="math display">\[
\TP = k,\, \TN = 0,\, \FP = n-k,\, \FN = 0.
\]</span></p>
<p>Its <em>F</em>₁ score is thus</p>
<p><span class="math display">\[
\frac{2\TP}{2\TP+\FN+\FP} = \frac{2k}{2k+n-k} = \frac{2k}{k+n}.
\]</span></p>
<p>If the fraction of funded samples in the test set is <span class="math inline">\(k/n=a\)</span>, then the accuracy of this classifier is <span class="math inline">\(a\)</span>. Its <em>F</em>₁ score is <span class="math inline">\(2a/(1+a)\)</span>, which is larger than <span class="math inline">\(a\)</span> unless <span class="math inline">\(a=1\)</span>. That’s because the true positives greatly outweigh the other confusion matrix values.</p>
<p>The balanced accuracy is</p>
<p><span class="math display">\[
\frac{1}{2} \left(\frac{\TP}{\TP+\FN} + \frac{\TN}{\TN+\FP} \right)  = \frac{1}{2},
\]</span></p>
<p>independently of <span class="math inline">\(a\)</span>. This quantity is sensitive to the low specificity.</p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:400px">
<div style="position:relative;padding-bottom:71.25%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_ef7mli52&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_pch0h80o" width="400" height="285" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.4" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0">
</iframe>
</div>
</div>
</div></div></section>
<section id="multiclass-classifiers" class="level3 page-columns page-full" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="multiclass-classifiers"><span class="header-section-number">3.2.3</span> Multiclass classifiers</h3>
<p>When there are more than two unique possible labels, these metrics can be applied using the <strong>one-vs-rest</strong> paradigm. For <span class="math inline">\(K\)</span> unique labels, this paradigm poses <span class="math inline">\(K\)</span> binary questions: “Is it in class 1, or not?”, “Is it in class 2, or not?”, etc. The confusion matrix becomes <span class="math inline">\(K\times K\)</span>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_hfixb8l6&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_eup2cbdf" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.2.3" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div id="exm-class-multiclass" class="theorem example" data-chapter="3" type="💻" data-description="Multiclass metrics">
<p><span class="theorem-title"><strong>Example 3.5 </strong></span>We load a dataset on the characteristics of cars and use quantitative factors to predict the region of origin:</p>
<div id="98fbbdb9" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>cars <span class="op">=</span> sns.load_dataset(<span class="st">"mpg"</span>).dropna()</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>cars.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">cylinders</th>
<th data-quarto-table-cell-role="th">displacement</th>
<th data-quarto-table-cell-role="th">horsepower</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">acceleration</th>
<th data-quarto-table-cell-role="th">model_year</th>
<th data-quarto-table-cell-role="th">origin</th>
<th data-quarto-table-cell-role="th">name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>18.0</td>
<td>8</td>
<td>307.0</td>
<td>130.0</td>
<td>3504</td>
<td>12.0</td>
<td>70</td>
<td>usa</td>
<td>chevrolet chevelle malibu</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>15.0</td>
<td>8</td>
<td>350.0</td>
<td>165.0</td>
<td>3693</td>
<td>11.5</td>
<td>70</td>
<td>usa</td>
<td>buick skylark 320</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>18.0</td>
<td>8</td>
<td>318.0</td>
<td>150.0</td>
<td>3436</td>
<td>11.0</td>
<td>70</td>
<td>usa</td>
<td>plymouth satellite</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>16.0</td>
<td>8</td>
<td>304.0</td>
<td>150.0</td>
<td>3433</td>
<td>12.0</td>
<td>70</td>
<td>usa</td>
<td>amc rebel sst</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>17.0</td>
<td>8</td>
<td>302.0</td>
<td>140.0</td>
<td>3449</td>
<td>10.5</td>
<td>70</td>
<td>usa</td>
<td>ford torino</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now we extract the quantitative features and labels:</p>
<div id="1a8c09df" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [<span class="st">"cylinders"</span>, <span class="st">"horsepower"</span>, <span class="st">"weight"</span>, <span class="st">"acceleration"</span>, <span class="st">"mpg"</span>]</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> cars[features]</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> pd.Categorical(cars[<span class="st">"origin"</span>])</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape[<span class="dv">0</span>], <span class="st">"samples and"</span>, X.shape[<span class="dv">1</span>], <span class="st">"features"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>392 samples and 5 features</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>It’s not necessary to convert a vector of strings into a <code>Categorical</code> vector of labels, but it does make a few things handy in post-processing.</p>
</div>
</div>
<p>Next, we split into training and testing subsets:</p>
<div id="9377072c" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>  X, y, </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>  test_size<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>  shuffle<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>  random_state<span class="op">=</span><span class="dv">1</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we perform the fit and measure the accuracy:</p>
<div id="a546a646" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"accuracy is </span><span class="sc">{</span>accuracy_score(y_test, yhat)<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>accuracy is 77.2%</code></pre>
</div>
</div>
<p>Here is the confusion matrix:</p>
<div id="570cf427" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> y.categories</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> confusion_matrix(y_test, yhat, labels<span class="op">=</span>labels)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay(C, display_labels<span class="op">=</span>labels).plot()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-31-output-1.png" width="534" height="429"></p>
</div>
</div>
<p>From the confusion matrix above we can see that, for example, out of 54 predictions of “usa” on the test set, there are 8 total false positives, in the sense that the actual labels were otherwise.</p>
<p>We also get <span class="math inline">\(K\)</span> versions of the metrics like accuracy, recall, <em>F</em>₁ score, and so on. We can get all the individual precision scores, say, automatically:</p>
<div id="325d1a8f" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>precisions <span class="op">=</span> precision_score(y_test, yhat, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (label,p) <span class="kw">in</span> <span class="bu">zip</span>(labels,precisions): </span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>p<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>europe: 62.5%
japan: 58.8%
usa: 85.2%</code></pre>
</div>
</div>
<p>To get a composite precision score, we have to specify an averaging method. The <code>"macro"</code> option simply takes the mean of the vector above.</p>
<div id="04c5e9f2" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>mac <span class="op">=</span> precision_score(y_test, yhat, average<span class="op">=</span><span class="st">"macro"</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mac)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.6883623819898329</code></pre>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_1qocbyij&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_3uoamfln" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.5" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><p>There are other ways to average performance scores over the classes, depending on whether poorly represented classes should be weighted more weakly than others.</p>
</section>
</section>
<section id="decision-trees" class="level2 page-columns page-full" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="decision-trees"><span class="header-section-number">3.3</span> Decision trees</h2>
<p>A decision tree is much like playing Twenty Questions. A question is asked, and the answer reduces the possible results, leading to a new question. <strong>CART</strong> (Classification And Regression Tree), which we present here, is a popular method for systematizing the idea.</p>
<p>Given feature vectors <span class="math inline">\(\bfx_1,\ldots,\bfx_n\)</span> with labels <span class="math inline">\(y_1,\ldots,y_n\)</span>, the immediate goal is to partition the samples into two subsets, each of which has as uniform as set of labels as possible. The process is then repeated recursively: the subsets are bisected to make four subsets, and so on. These splits form a binary tree. When a prediction is required, we apply the same criteria as the splits in our tree, and when we reach a <em>leaf</em> of the tree (i.e., no further subdivisions), we take a vote of all the samples in the leaf subset to determine the label.</p>
<p>There are two details that need to be specified: what kind of subset splits to allow, and how to determine the uniformity of labels within each subset. We start with the latter.</p>
<section id="gini-impurity" class="level3 page-columns page-full" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="gini-impurity"><span class="header-section-number">3.3.1</span> Gini impurity</h3>
<div id="def-class-indicator" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.4 </strong></span>Let <span class="math inline">\(k\)</span> be an integer. The <strong>indicator function</strong> <span class="math inline">\(\mathbb{1}_k\)</span> is the function on integers defined as <span class="math display">\[
\mathbb{1}_k(t) = \begin{cases}
  1, &amp; \text{if } t=k, \\
  0, &amp; \text{otherwise.}
  \end{cases}
\]</span></p>
</div>
<p>Let <span class="math inline">\(S\)</span> be any subset of samples, given as a list of indices into the original set. Suppose there are <span class="math inline">\(K\)</span> unique labels, which we denote <span class="math inline">\(1,2,\ldots,K\)</span>. Define the values</p>
<p><span id="eq-class-prop-samples"><span class="math display">\[
p_k = \frac{1}{ |S| } \sum_{i\in S} \mathbb{1}_k(y_i), \qquad k=1,\ldots,K,
\tag{3.1}\]</span></span></p>
<p>where <span class="math inline">\(|S|\)</span> is the number of elements in <span class="math inline">\(S\)</span>. In words, <span class="math inline">\(p_k\)</span> is the proportion of samples in <span class="math inline">\(S\)</span> that have label <span class="math inline">\(k\)</span>. Note that the sum over all the <span class="math inline">\(p_k\)</span> equals 1.</p>
<div id="def-class-gini" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.5 </strong></span>The <strong>Gini impurity</strong> of sample set <span class="math inline">\(S\)</span> is defined as <span class="math display">\[
H(S) = \sum_{k=1}^K p_k(1-p_k),
\]</span> where <span class="math inline">\(p_k\)</span> is defined in <a href="#eq-class-prop-samples" class="quarto-xref">Equation&nbsp;<span>3.1</span></a>.</p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_2fy3h53b&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_o52kj8wl" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.3.1" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><p>If one of the <span class="math inline">\(p_k\)</span> is 1, then the others are all zero and <span class="math inline">\(H(S)=0\)</span>. This is considered optimal—it indicates that all the labels in the set <span class="math inline">\(S\)</span> are identical.</p>
<p>At the other extreme, if <span class="math inline">\(p_k=1/K\)</span> for all <span class="math inline">\(k\)</span>, then <span class="math display">\[
H(S) = \sum_{k=1}^K \frac{1}{K} \left(1 - \frac{1}{K} \right) = K\cdot \frac{1}{K}\cdot\frac{K-1}{K} = \frac{K-1}{K} &lt; 1.
\]</span> In general, <span class="math inline">\(H\)</span> is always nonnegative and less than 1, and it only approaches 1 in the limit of a large number of equally distributed classes.</p>
<div id="exm-class-gini" class="theorem example" data-chapter="3" type="✍️" data-description="Gini impurity">
<p><span class="theorem-title"><strong>Example 3.6 </strong></span>Suppose a set <span class="math inline">\(S\)</span> has <span class="math inline">\(n\)</span> members with label A, 1 member with label B, and 1 member with label C. What is the Gini impurity of <span class="math inline">\(S\)</span>?</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>We have <span class="math inline">\(p_A=n/(n+2)\)</span>, <span class="math inline">\(p_B=p_C=1/(n+2)\)</span>. Hence</p>
<p><span class="math display">\[
\begin{split}
    H(S) &amp;= \frac{n}{n+2}\left( 1 - \frac{n}{n+2} \right) + 2 \frac{1}{n+2}\left( 1 - \frac{1}{n+2} \right) \\
    &amp;= \frac{n}{n+2}\frac{2}{n+2} + \frac{2}{n+2}\frac{n+1}{n+2} \\
    &amp;= \frac{4n+2}{(n+2)^2}.
\end{split}
\]</span></p>
<p>This value is 1/2 for <span class="math inline">\(n=0\)</span> and approaches zero as <span class="math inline">\(n\to\infty\)</span>.</p>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:400px">
<div style="position:relative;padding-bottom:71.25%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_6j5svtw2&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_wtimf6z2" width="400" height="285" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.6" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0">
</iframe>
</div>
</div>
</div></div></section>
<section id="partitioning" class="level3 page-columns page-full" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="partitioning"><span class="header-section-number">3.3.2</span> Partitioning</h3>
<p>Suppose we start with a sample set <span class="math inline">\(S\)</span> that we partition into disjoint (i.e., nonoverlapping) subsets <span class="math inline">\(S_L\)</span> and <span class="math inline">\(S_R\)</span>. We want to assign a total impurity to the partitioning so that we can compare different scenarios. One pitfall we should avoid is to put just one sample into <span class="math inline">\(S_L\)</span> and all the rest into <span class="math inline">\(S_R\)</span>, which would make <span class="math inline">\(H(S_L)=0\)</span> automatically and give an advantage. So we will choose a formula that rewards more evenly divided subsets.</p>
<div id="def-class-impurity" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.6 </strong></span>The <strong>total impurity</strong> of the partition <span class="math inline">\((S_L,S_R)\)</span> is <span class="math display">\[
Q(S_L,S_R) = \lvert S_L\rvert\, H(S_L) + \lvert S_R \rvert \, H(S_R).
\]</span></p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_xw3wpe9m&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_8sa79t5k" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.3.2" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><p>If <span class="math inline">\(S_L\)</span> and <span class="math inline">\(S_R\)</span> are both pure subsets, then <span class="math inline">\(Q(S_L,S_R)=0\)</span>. Otherwise, <span class="math inline">\(Q\)</span> tends to be larger in response to less purity and greater size in the subsets.</p>
<p>Our goal is to choose a partition that minimizes <span class="math inline">\(Q\)</span>. However, we constrain ourselves to allow only certain kinds of partitions. If feature space is <span class="math inline">\(d\)</span>-dimensional, we select a dimension <span class="math inline">\(1 \le j \le d\)</span> and a real threshold value <span class="math inline">\(\theta\)</span>. Then each feature vector <span class="math inline">\(\bfx\)</span> is placed in <span class="math inline">\(S_L\)</span> if <span class="math inline">\(x_j \le \theta\)</span> and in <span class="math inline">\(S_R\)</span> if <span class="math inline">\(x_j &gt; \theta\)</span>. Geometrically, we are dividing feature space by an axis-aligned line if <span class="math inline">\(d=2\)</span> or an axis-aligned plane if <span class="math inline">\(d=3\)</span>. This splitting criterion can be evaluated extremely quickly, and we can find the best possible such partitioning in the sense of minimizing <span class="math inline">\(Q(S_L,S_R)\)</span> in a reasonable amount of time.</p>
<div id="exm-class-tree-partition" class="theorem example" data-chapter="3" type="✍️" data-description="Tree partitioning">
<p><span class="theorem-title"><strong>Example 3.7 </strong></span>Suppose we have <span class="math inline">\(d=1\)</span> feature and are given the four samples <span class="math inline">\((X_i,y_i) = \{ (0,A), (1,B), (2,A), (3,B) \}\)</span>. What is the optimal partition?</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>We can partition into two pieces based on a threshold value <span class="math inline">\(\theta\)</span>: <span class="math inline">\(\{x \le \theta\}\)</span> and <span class="math inline">\(\{x &gt; \theta\}\)</span>. But there are really only 5 different cases.</p>
<table class="table">
<colgroup>
<col style="width: 48%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(\theta\)</span></th>
<th style="text-align: center;">Left</th>
<th style="text-align: center;">Right</th>
<th style="text-align: center;"><span class="math inline">\(Q\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\(&lt; 0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\varnothing\)</span>, <span class="math inline">\(H=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\([A, B, A, B]\)</span>, <span class="math inline">\(H=\tfrac{1}{2}\cdot \tfrac{1}{2} + \tfrac{1}{2}\cdot \tfrac{1}{2} =\tfrac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\cdot 0 + 4\cdot \tfrac{1}{2} = 2\)</span></td>
</tr>
<tr class="even">
<td style="text-align: right;"><span class="math inline">\([0,1)\)</span></td>
<td style="text-align: center;"><span class="math inline">\([A]\)</span>, <span class="math inline">\(H=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\([B, A, B]\)</span>, <span class="math inline">\(H=\tfrac{2}{3}\cdot \tfrac{1}{3} + \tfrac{1}{3}\cdot \tfrac{2}{3} =\tfrac{4}{9}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1 \cdot 0 + 3 \cdot\tfrac{4}{9} = \tfrac{4}{3}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\([1,2)\)</span></td>
<td style="text-align: center;"><span class="math inline">\([A, B]\)</span>, <span class="math inline">\(H=\tfrac{1}{2}\cdot \tfrac{1}{2} + \tfrac{1}{2}\cdot \tfrac{1}{2} =\tfrac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\([A, B]\)</span>, <span class="math inline">\(H=\tfrac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(2 \cdot \tfrac{1}{2} + 2 \cdot\tfrac{1}{2} = 2\)</span></td>
</tr>
<tr class="even">
<td style="text-align: right;"><span class="math inline">\([2,3)\)</span></td>
<td style="text-align: center;"><span class="math inline">\([A,B,A]\)</span>, <span class="math inline">\(H=\tfrac{2}{3}\cdot \tfrac{1}{3} + \tfrac{1}{3}\cdot \tfrac{2}{3} =\tfrac{4}{9}\)</span></td>
<td style="text-align: center;"><span class="math inline">\([B]\)</span>, <span class="math inline">\(H=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(3 \cdot\tfrac{4}{9} + 1\cdot 0= \tfrac{4}{3}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\(\ge 3\)</span></td>
<td style="text-align: center;"><span class="math inline">\([A, B, A, B]\)</span>, <span class="math inline">\(H=\tfrac{1}{2}\cdot \tfrac{1}{2} + \tfrac{1}{2}\cdot \tfrac{1}{2} =\tfrac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\varnothing\)</span>, <span class="math inline">\(H=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(4\cdot \tfrac{1}{2} + 0\cdot 0 = 2\)</span></td>
</tr>
</tbody>
</table>
<p>Both <span class="math inline">\(\{ (0,A) \}, \{ (1,B), (2,A), (3,B) \}\)</span> and <span class="math inline">\(\{ (0,A), (1,B), (2,A) \}, \{ (3,B) \}\)</span> are equally optimal partitionings, with <span class="math inline">\(Q=4/3\)</span>.</p>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:400px">
<div style="position:relative;padding-bottom:71.25%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_e1w27rpl&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_nr8bd4u5" width="400" height="285" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.7" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0">
</iframe>
</div>
</div>
</div></div><p>Finally, once we have found the optimal way to split <span class="math inline">\(S\)</span> into <span class="math inline">\((S_L,S_R)\)</span>, we need to check whether it is an improvement—that is, whether <span class="math display">\[
Q(S_L,S_R) + \alpha &lt; Q(S,\varnothing) = |S| H(S),
\]</span> where <span class="math inline">\(\alpha\)</span> is an optional nonnegative number that requires a certain minimum amount of decrease. If the condition is satisfied, then <span class="math inline">\(S\)</span> is not split and becomes a leaf of the decision tree. If so, then we add this split to the binary tree and recursively check both <span class="math inline">\(S_L\)</span> and <span class="math inline">\(S_R\)</span> for partitioning.</p>
<p>The above strategy is fast but can fail to get the best possible decision tree. That is, the optimal partition into 4 or 8 subsets might require you to look ahead in order to avoid a good-looking first partition that leads you astray. Because the optimization algorithm considers only one level at a time, we say it is a <em>greedy</em> approach.</p>
</section>
<section id="decision-boundary" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="decision-boundary"><span class="header-section-number">3.3.3</span> Decision boundary</h3>
<p>One way to think about a classifier is that it divides all of feature space into zones belonging to the different classes. The boundary between two zones is the set of points where the classifier is indifferent between the two classes; together, the boundary points form the <strong>decision boundary</strong>.</p>
<p>For a decision tree, the decision boundary is always perpendicular to the feature axes, as illustrated in this animation:</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="_media/dtree_demo.mp4"></video></div>
<p>Initially, when the tree has a depth of 1, all of feature space is divided into two zones. At each new depth the tree is able to add more zones, and the decision boundary gradually becomes more complex.</p>
</section>
<section id="usage-and-interpretation" class="level3 page-columns page-full" data-number="3.3.4">
<h3 data-number="3.3.4" class="anchored" data-anchor-id="usage-and-interpretation"><span class="header-section-number">3.3.4</span> Usage and interpretation</h3>
<p>In naive form, the decision tree construction continues to find partitions until every leaf in the tree represents a pure subset. In practice, we usually set a limit on the depth of the tree, which is the maximum number of partitions it takes to start from the root and reach any leaf. This obviously puts an upper limit on the computational time, but it is also desirable for other reasons we will explore in the next chapter.</p>
<div id="exm-class-tree-toy" class="theorem example" data-chapter="3" type="💻" data-description="Inspecting a decision tree">
<p><span class="theorem-title"><strong>Example 3.8 </strong></span>We create a toy dataset with 20 random points in the plane, with two subsets of 10 that are shifted left/right a bit. (The details are not important.) Here is how the set looks:</p>
<div id="87365f69" class="cell" data-execution_count="34">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> default_rng</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> default_rng(<span class="dv">1</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>gp1 <span class="op">=</span> rng.random((<span class="dv">10</span>,<span class="dv">2</span>))</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>gp1[:,<span class="dv">0</span>] <span class="op">-=</span> <span class="fl">0.25</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>gp2 <span class="op">=</span> rng.random((<span class="dv">10</span>,<span class="dv">2</span>))</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>gp2[:,<span class="dv">0</span>] <span class="op">+=</span> <span class="fl">0.25</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack((gp1,gp2))</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.hstack(([<span class="dv">1</span>]<span class="op">*</span><span class="dv">10</span>,[<span class="dv">2</span>]<span class="op">*</span><span class="dv">10</span>))</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"feature matrix X:"</span>)</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X)</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">label vector y:"</span>)</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>feature matrix X:
[[ 0.26182162  0.9504637 ]
 [-0.10584039  0.94864945]
 [ 0.06183145  0.42332645]
 [ 0.57770259  0.40919914]
 [ 0.29959369  0.02755911]
 [ 0.50351311  0.53814331]
 [ 0.07973172  0.7884287 ]
 [ 0.05319483  0.45349789]
 [-0.1159583   0.40311299]
 [-0.04654476  0.26231334]
 [ 1.00036467  0.28040876]
 [ 0.73519097  0.9807372 ]
 [ 1.21165719  0.72478994]
 [ 0.79122686  0.2768912 ]
 [ 0.41065201  0.96992541]
 [ 0.76606859  0.11586561]
 [ 0.87348976  0.77668311]
 [ 0.8630033   0.9172977 ]
 [ 0.28959288  0.52858926]
 [ 0.70933588  0.06234958]]

label vector y:
[1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]</code></pre>
</div>
</div>
<p>The features are the two point coordinates, giving a 20-by-2 feature matrix <code>X</code>, and the labels are a vector <code>y</code> of length 20. We will create a data frame for aiding in visualization:</p>
<div id="c8b12a62" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame( {<span class="st">"x₁"</span>:X[:,<span class="dv">0</span>], <span class="st">"x₂"</span>:X[:,<span class="dv">1</span>], <span class="st">"y"</span>:y} )</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"x₁"</span>, y<span class="op">=</span><span class="st">"x₂"</span>, hue<span class="op">=</span><span class="st">"y"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-35-output-1.png" width="589" height="429"></p>
</div>
</div>
<p>Now we create and fit a decision tree for these samples:</p>
<div id="b8bde660" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>tree.fit(X,y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>DecisionTreeClassifier(max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked=""><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">DecisionTreeClassifier</label><div class="sk-toggleable__content"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div>
</div>
</div>
<p>At this point, the <code>tree</code> object has created and stored all the information derived from the dataset that defines the decision tree. Since this is a small tree, we can easily look under the hood:</p>
<div id="44f5b5a8" class="cell" data-execution_count="37">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> figure</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>figure(figsize<span class="op">=</span>(<span class="dv">18</span>,<span class="dv">11</span>), dpi<span class="op">=</span><span class="dv">160</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>plot_tree(tree, feature_names<span class="op">=</span>[<span class="st">"x₁"</span>, <span class="st">"x₂"</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-37-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The root of the tree at the top shows that the best initial split was found at the vertical line <span class="math inline">\(x_1=0.644\)</span>. To the right of that line is a Gini value of zero: 8 samples, all with label 2. That is, any future prediction by this tree will immediately return label 2 if its value for <span class="math inline">\(x_1\)</span> exceeds 0.644. Otherwise, it moves to the left child node and tests whether <span class="math inline">\(x_2\)</span> is greater than <span class="math inline">\(0.96\)</span>. As you can see from the scatterplot above, that horizontal line has a single sample with label 2 above it. And so on.</p>
<p>Notice that the bottom right node has a nonzero final Gini impurity. This node could be partitioned, but the classifier was constrained to stop at a depth of 3. If a prediction ends up here, then the classifier returns label 1, which is the most likely outcome.</p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_nqwoof7u&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_dyxb6uzv" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.8" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><p>Because we can follow a decision tree’s logic step by step, we say it is highly <strong>interpretable</strong>. The transparency of the prediction algorithm is an attractive aspect of decision trees, although this advantage can weaken as the power of the tree is increased to handle difficult datasets.</p>
<div id="exm-class-tree-penguins" class="theorem example" data-chapter="3" type="💻" data-description="Tree classifier for the penguins dataset">
<p><span class="theorem-title"><strong>Example 3.9 </strong></span>We return to the penguins and fit a decision tree to the quantitative features:</p>
<div id="107883a7" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>pen <span class="op">=</span> sns.load_dataset(<span class="st">"penguins"</span>)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>pen <span class="op">=</span> pen.dropna()</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"bill_length_mm"</span>,</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"bill_depth_mm"</span>,</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"flipper_length_mm"</span>,</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"body_mass_g"</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pen[features]</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> pen[<span class="st">"species"</span>]</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>dt <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>dt.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>DecisionTreeClassifier(max_depth=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked=""><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">DecisionTreeClassifier</label><div class="sk-toggleable__content"><pre>DecisionTreeClassifier(max_depth=4)</pre></div></div></div></div></div>
</div>
</div>
<p>We get some interesting information from looking at the top levels of a decision tree trained on the full dataset:</p>
<div id="4bf6109d" class="cell" data-execution_count="39">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> figure</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>figure(figsize<span class="op">=</span>(<span class="dv">18</span>,<span class="dv">11</span>), dpi<span class="op">=</span><span class="dv">160</span>)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>plot_tree(dt, max_depth<span class="op">=</span><span class="dv">2</span>, feature_names<span class="op">=</span>features)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-39-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The most determinative feature for identifying the species is apparently the flipper length. If it exceeds 206.5 mm, then the penguin is rather likely to be a Gentoo.</p>
<p>We can measure the relative importance of each feature by comparing their total contributions to reducing the Gini index:</p>
<div id="bf25f16c" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>pd.Series(dt.feature_importances_, index<span class="op">=</span>features)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>bill_length_mm       0.381063
bill_depth_mm        0.051434
flipper_length_mm    0.553866
body_mass_g          0.013638
dtype: float64</code></pre>
</div>
</div>
<p>This ranking is known as <strong>Gini importance</strong>.</p>
<p>Flipper length alone accounts for about half of the resolving power of the tree, followed in importance by the bill length. The other measurements apparently have little discriminative value.</p>
<p>In order to assess the effectiveness of the tree, we use the train–test paradigm:</p>
<div id="7d8d120b" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix,classification_report</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>  X, y,</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>  test_size<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>  shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>  random_state<span class="op">=</span><span class="dv">0</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>dt.fit(X_train, y_train)</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> dt.predict(X_test)</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion matrix:"</span>)</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( confusion_matrix(</span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>  y_test, yhat, </span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>  labels<span class="op">=</span>[<span class="st">"Adelie"</span>, <span class="st">"Chinstrap"</span>, <span class="st">"Gentoo"</span>]</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>  ) )</span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Performance metrics:"</span>)</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( classification_report(y_test, yhat) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion matrix:
[[39  0  0]
 [ 2  8  0]
 [ 1  0 17]]

Performance metrics:
              precision    recall  f1-score   support

      Adelie       0.93      1.00      0.96        39
   Chinstrap       1.00      0.80      0.89        10
      Gentoo       1.00      0.94      0.97        18

    accuracy                           0.96        67
   macro avg       0.98      0.91      0.94        67
weighted avg       0.96      0.96      0.95        67
</code></pre>
</div>
</div>
<p>The performance is quite good, although the Chinstrap case is hindered by the relatively low number of training examples:</p>
<div id="f9e8fa03" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>y_train.value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>Adelie       107
Gentoo       101
Chinstrap     58
Name: species, dtype: int64</code></pre>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_q2w2n6cs&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_mllwanmt" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.9" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><p>Decision trees can depend sensitively on the sample locations; a small change might completely rewrite large parts of the tree, in which case interpretability becomes less clear.</p>
</section>
</section>
<section id="nearest-neighbors" class="level2 page-columns page-full" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="nearest-neighbors"><span class="header-section-number">3.4</span> Nearest neighbors</h2>
<p>The next learner type is conceptually simple: given a point in feature space to classify, survey the nearest known examples and choose the most frequently occurring class. This is called the <strong><span class="math inline">\(k\)</span> nearest neighbors</strong> (kNN or <span class="math inline">\(k\)</span>-NN) algorithm, where <span class="math inline">\(k\)</span> is the number of neighboring examples to survey.</p>
<section id="distances-and-norms" class="level3 page-columns page-full" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="distances-and-norms"><span class="header-section-number">3.4.1</span> Distances and norms</h3>
<p>The existence of “closest” examples means that we need to define a notion of distance in feature spaces of any dimension. Let <span class="math inline">\(\real^d\)</span> be the space of vectors with <span class="math inline">\(d\)</span> real components, and let <span class="math inline">\(\bfzero\)</span> be the vector of all zeros.</p>
<div id="def-class-metric" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.7 </strong></span>A <strong>distance metric</strong> is a function <span class="math inline">\(\dist\)</span> on pairs of vectors that satisfies the following properties for all vectors <span class="math inline">\(\bfu\)</span>, <span class="math inline">\(\bfv\)</span>, and <span class="math inline">\(\bfz\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\dist(\bfu,\bfv) \ge 0\)</span>,</li>
<li><span class="math inline">\(\dist(\bfu,\bfv)=0\)</span> if and only if <span class="math inline">\(\bfu=\bfv\)</span>,</li>
<li><span class="math inline">\(\dist(\bfu,\bfv) = \dist(\bfv,\bfu)\)</span>, and</li>
<li><span class="math inline">\(\dist(\bfu,\bfv) \le \dist(\bfu,\bfz) + \dist(\bfz,\bfv)\)</span>, known as the triangle inequality.</li>
</ol>
</div>
<p>These are considered the essential properties desired of a distance metric. We will define a distance metric by using a function on vectors known as a <em>norm</em>.</p>
<div id="def-class-norm" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.8 </strong></span>For any vector <span class="math inline">\(\bfu \in \real^d\)</span>, we define the following norms.</p>
<ul>
<li>The <strong>2-norm</strong> or <em>Euclidean norm</em>: <span class="math display">\[
\twonorm{\bfu} = \bigl(u_1^2 + u_2^2 + \cdots + u_d^2\bigr)^{1/2}.
\]</span></li>
<li>The <strong>1-norm</strong> or <em>Manhattan norm</em>: <span class="math display">\[
\onenorm{\bfu} = |u_1| + |u_2| + \cdots + |u_d|.
\]</span></li>
<li>The <strong><span class="math inline">\(\infty\)</span>-norm</strong>, <em>max norm</em>, or <em>Chebyshev norm</em>: <span class="math display">\[
\infnorm{\bfu} = \max_{1\le i \le d} \abs{u_i}.
\]</span></li>
</ul>
<!-- A **norm** is a function $\norm{\bfu}$ on $\real^d$ that satisfies the following properties:

$$
\begin{split}
\norm{\bfzero} &= 0,  \\ 
\norm{\bfu} &> 0 \text{ if $\bfu$ is a nonzero vector}, \\ 
\norm{c\bfu} &= |c| \, \norm{u} \text{ for any real number $c$}, \\ 
\norm{\bfu + \bfv } &\le \norm{\bfu} + \norm{\bfv} 
\end{split}
$$ -->
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_w85a5am5&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_579yxing" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.4.1" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><p>Given a norm, the distance between vectors <span class="math inline">\(\bfu\)</span> and <span class="math inline">\(\bfv\)</span> is defined by <span class="math display">\[
\dist(\bfu,\bfv) = \norm{\bfu - \bfv}.
\]</span></p>
<div id="exm-class-distance" class="theorem example" data-chapter="3" type="✍️" data-description="Calculating distance">
<p><span class="theorem-title"><strong>Example 3.10 </strong></span>Given <span class="math inline">\(\bfu=[-1,1,0,4]\)</span> and <span class="math inline">\(\bfv=[-2,1,2,2]\)</span>, find the distance between them using all three common norms.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>We first calculate <span class="math inline">\(\bfu - \bfv = [-3,0,-2,2]\)</span>. Then <span class="math display">\[
\begin{split}
\twonorm{\bfu-\bfv} &amp;= \bigl( 3^2 + 0^2 + 2^2 + 2^2 \bigr)^{1/2} = \sqrt{17}, \\
\onenorm{\bfu-\bfv} &amp;= 3  + 0 + 2 + 2 = 7, \\
\infnorm{\bfu-\bfv} &amp;= \max\{ 3, 0, 2, 2 \} = 3.
\end{split}
\]</span></p>
</div>
</div>
<p>The Euclidean norm generalizes ordinary geometric distance in <span class="math inline">\(\real^2\)</span> and <span class="math inline">\(\real^3\)</span> and is usually considered the default. One of its most important features is that <span class="math inline">\(\twonorm{\bfx}^2\)</span> is a differentiable function of the components of <span class="math inline">\(\bfx\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>When <span class="math inline">\(\norm{\,}\)</span> is used with no subscript, it’s usually meant to be the 2-norm, but it can also mean a generic, unspecified norm.</p>
</div>
</div>
</section>
<section id="algorithm" class="level3 page-columns page-full" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="algorithm"><span class="header-section-number">3.4.2</span> Algorithm</h3>
<p>As data, we are given labeled samples <span class="math inline">\(\bfx_1,\ldots,\bfx_n\)</span> in <span class="math inline">\(\real^d\)</span>.</p>
<div id="def-class-knn" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.9 </strong></span>Given a new query vector <span class="math inline">\(\bfx\)</span>, the <strong>kNN algorithm</strong> finds the <span class="math inline">\(k\)</span> labeled samples closest to <span class="math inline">\(\bfx\)</span> and chooses the most frequently occurring label among them. Ties are broken randomly.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <em>nearest neighbor search</em> is a well-studied problem in computer science, and there are specialized data structures used for its efficient solution.</p>
</div>
</div>
<div id="exm-class-knn-small" class="theorem example" data-chapter="3" type="✍️" data-description="kNN classifier">
<p><span class="theorem-title"><strong>Example 3.11 </strong></span>Here are 6 sample points, labeled blue and red, in 2-dimensional feature space:</p>
<p><img src="_media/knn_example1.svg" class="img-fluid"></p>
<p>Using inf-norm distance and <span class="math inline">\(k=3\)</span>, find the kNN labels at the locations marked A and B.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>At point A, the nearest samples are at <span class="math inline">\((0,2)\)</span> with distance <span class="math inline">\(1\)</span>, <span class="math inline">\((0,0)\)</span> with distance <span class="math inline">\(1\)</span>, and <span class="math inline">\((2,1)\)</span> with distance <span class="math inline">\(1.5\)</span>. By a 2-1 vote, the point should be labeled blue.</p>
<p>At point B, the nearest samples are at <span class="math inline">\((0,0)\)</span> with distance 1, <span class="math inline">\((-2,-1)\)</span> with distance 1, and <span class="math inline">\((0,-2)\)</span> with distance <span class="math inline">\(1.5\)</span>. By a 2-1 vote, the point should be labeled red.</p>
<p>Note that the blue sample point at <span class="math inline">\((0,-2)\)</span> is its own closest neighbor, but the next two nearest neighbors are red. Therefore, in kNN with <span class="math inline">\(k=3\)</span>, the red points will outvote it and predict red! As always, we should not expect perfect performance on the training set.</p>
</div>
</div>
<p>kNN effectively divides up the feature space into domains that are dominated by nearby instances. The evolution of the decision boundary is illustrated here for two features using 2-norm distance:</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video2" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="_media/knn_demo.mp4"></video></div>
<p>At <span class="math inline">\(k=1\)</span> neighbor, each sample point defines its own local domain of influence that gives way when reaching a point equally close to a differently-labeled sample. This typically produces the most complicated decision boundaries. At the other extreme, with <span class="math inline">\(k=n\)</span> neighbors, all the samples vote every time, so all of feature space is given the same label (pending tiebreakers).</p>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_5gh9td14&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_eflwm15d" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.4.2" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div id="exm-class-knn" class="theorem example" data-chapter="3" type="💻" data-description="kNN classifier for the penguins dataset">
<p><span class="theorem-title"><strong>Example 3.12 </strong></span>Back to the penguins! We use <code>dropna</code> to drop any rows with missing values.</p>
<div id="781d9a3a" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>penguins <span class="op">=</span> sns.load_dataset(<span class="st">"penguins"</span>)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>penguins <span class="op">=</span> penguins.dropna()</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>penguins.head(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">species</th>
<th data-quarto-table-cell-role="th">island</th>
<th data-quarto-table-cell-role="th">bill_length_mm</th>
<th data-quarto-table-cell-role="th">bill_depth_mm</th>
<th data-quarto-table-cell-role="th">flipper_length_mm</th>
<th data-quarto-table-cell-role="th">body_mass_g</th>
<th data-quarto-table-cell-role="th">sex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Adelie</td>
<td>Torgersen</td>
<td>39.1</td>
<td>18.7</td>
<td>181.0</td>
<td>3750.0</td>
<td>Male</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Adelie</td>
<td>Torgersen</td>
<td>39.5</td>
<td>17.4</td>
<td>186.0</td>
<td>3800.0</td>
<td>Female</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Adelie</td>
<td>Torgersen</td>
<td>40.3</td>
<td>18.0</td>
<td>195.0</td>
<td>3250.0</td>
<td>Female</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>Adelie</td>
<td>Torgersen</td>
<td>36.7</td>
<td>19.3</td>
<td>193.0</td>
<td>3450.0</td>
<td>Female</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>Adelie</td>
<td>Torgersen</td>
<td>39.3</td>
<td>20.6</td>
<td>190.0</td>
<td>3650.0</td>
<td>Male</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6</td>
<td>Adelie</td>
<td>Torgersen</td>
<td>38.9</td>
<td>17.8</td>
<td>181.0</td>
<td>3625.0</td>
<td>Female</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The data set has four quantitative columns that we use as features, and the species name is the label.</p>
<div id="2640e039" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"bill_length_mm"</span>,</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"bill_depth_mm"</span>,</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"flipper_length_mm"</span>,</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"body_mass_g"</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> penguins[features]</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> penguins[<span class="st">"species"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Each type of classifier has to be imported before its first use in a session. (Importing more than once does no harm.)</p>
<div id="e69e347f" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>knn.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked=""><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>
</div>
</div>
<p>We can manually find the neighbors of a new vector. However, we have to make the query in the form of a data frame, since that is how the training data was provided. Here we make a query frame for values very close to the ones in the first row of the data.</p>
<div id="2cd7021c" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>vals <span class="op">=</span> [<span class="dv">39</span>, <span class="dv">19</span>, <span class="dv">180</span>, <span class="dv">3750</span>]</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> pd.DataFrame([vals], columns<span class="op">=</span>features)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>dist, idx <span class="op">=</span> knn.kneighbors(query)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>idx[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>array([  0, 143,  53, 100, 153])</code></pre>
</div>
</div>
<p>The result above indicates that the first sample (index 0) was the closest, followed by four others. We can look up the labels of these points:</p>
<div id="75f897d8" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>y[ idx[<span class="dv">0</span>] ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>0         Adelie
143       Adelie
53        Adelie
100       Adelie
153    Chinstrap
Name: species, dtype: object</code></pre>
</div>
</div>
<p>By a vote of 4–1, then, the classifier should choose Adelie as the result at this location.</p>
<div id="daf9ff93" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>knn.predict(query)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>array(['Adelie'], dtype=object)</code></pre>
</div>
</div>
<p>Note that points can be outvoted by their neighbors. In other words, the classifier won’t necessarily be correct on every training sample. For example:</p>
<div id="a30051de" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted:"</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( knn.predict(X.iloc[:<span class="dv">5</span>,:]) )</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data:"</span>)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( y.iloc[:<span class="dv">5</span>].values )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted:
['Adelie' 'Adelie' 'Chinstrap' 'Adelie' 'Chinstrap']

Data:
['Adelie' 'Adelie' 'Adelie' 'Adelie' 'Adelie']</code></pre>
</div>
</div>
<p>Next, we split into training and test sets to gauge the performance of the classifier. The <code>classification_report</code> function creates a summary of some of the important metrics.</p>
<div id="1bc2b55c" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report,confusion_matrix</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>  X, y,</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>  test_size<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>  shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">302</span></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train,y_train)</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion matrix:"</span>)</span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( confusion_matrix(</span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>    y_test, yhat, </span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[<span class="st">"Adelie"</span>, <span class="st">"Chinstrap"</span>, <span class="st">"Gentoo"</span>]</span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>    ) )</span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Performance metrics:"</span>)</span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( classification_report(y_test, yhat) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion matrix:
[[34  2  2]
 [ 8  6  1]
 [ 1  0 13]]

Performance metrics:
              precision    recall  f1-score   support

      Adelie       0.79      0.89      0.84        38
   Chinstrap       0.75      0.40      0.52        15
      Gentoo       0.81      0.93      0.87        14

    accuracy                           0.79        67
   macro avg       0.78      0.74      0.74        67
weighted avg       0.79      0.79      0.77        67
</code></pre>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_i1xfob91&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_jt0572v9" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.12" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>The default norm in the kNN learner is the 2-norm. To use the 1-norm instead, add <code>metric="manhattan"</code> to the classifier construction call.</p>
</div>
</div>
</section>
<section id="standardization" class="level3 page-columns page-full" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="standardization"><span class="header-section-number">3.4.3</span> Standardization</h3>
<p>The values in the columns of the penguin frame in <a href="#exm-class-knn" class="quarto-xref">Example&nbsp;<span>3.12</span></a> are scaled quite differently. In particular, the values in the body mass column are more than 20x larger than the other columns on average:</p>
<div id="21665bfb" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>X.mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>bill_length_mm         43.992793
bill_depth_mm          17.164865
flipper_length_mm     200.966967
body_mass_g          4207.057057
dtype: float64</code></pre>
</div>
</div>
<p>Consequently, the mass feature will dominate the distance calculations. To remedy this issue, we could transform the data into z-scores:</p>
<div id="7c590f95" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> X.transform( <span class="kw">lambda</span> x: (x <span class="op">-</span> x.mean()) <span class="op">/</span> x.std() )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We could then retrain the classifier using <code>Z</code> in place of <code>X</code>. Scikit-learn allows us to automate this process by creating a <strong>pipeline</strong>, which makes it easy to chain together a data transformation followed by a learner.</p>
<div id="exm-class-knn-standard" class="theorem example" data-chapter="3" type="💻" data-description="Pipeline for standardized columns">
<p><span class="theorem-title"><strong>Example 3.13 </strong></span>Once created, a pipeline object can mostly be treated the same as any other learner:</p>
<div id="6dd2e94a" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler   <span class="co"># converts to z-scores</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> make_pipeline(StandardScaler(), knn)</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>pipe.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('standardscaler', StandardScaler()),
                ('kneighborsclassifier', KNeighborsClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('standardscaler', StandardScaler()),
                ('kneighborsclassifier', KNeighborsClassifier())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox"><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>
</div>
</div>
<p>In this case, standardization allows us to perform perfectly!</p>
<div id="71853d47" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> pipe.predict(X_test)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion matrix:"</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( confusion_matrix(</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>    y_test, yhat, </span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[<span class="st">"Adelie"</span>, <span class="st">"Chinstrap"</span>, <span class="st">"Gentoo"</span>]</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>    ) )</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Performance metrics:"</span>)</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( classification_report(y_test, yhat) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion matrix:
[[38  0  0]
 [ 0 15  0]
 [ 0  0 14]]

Performance metrics:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        38
   Chinstrap       1.00      1.00      1.00        15
      Gentoo       1.00      1.00      1.00        14

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67
</code></pre>
</div>
</div>
<p>We can look under the hood of the pipeline. For example, we can see that the mean and variance of each of the original data columns is stored in the first part of the pipeline:</p>
<div id="743ee24a" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( pipe[<span class="dv">0</span>].mean_ )</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( pipe[<span class="dv">0</span>].var_ )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[  44.18759398   17.01503759  202.04135338 4266.72932331]
[3.00582295e+01 3.98263101e+00 1.94114831e+02 6.53423137e+05]</code></pre>
</div>
</div>
<p>However, we don’t need to access that data just to use the pipeline. That’s taken care of when we use <code>pipe.score</code> or <code>pipe.predict</code>.</p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_swqmj45e&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_ghyc5qas" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.13" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><p>The <code>StandardScaler</code>, which converts each column (feature) into z-scores, is appropriate for data that is roughly normally distributed. For other distributions, or if there are many outliers, it may be better to use the <code>RobustScaler</code>, which instead centers on the median and scales using the IQR. Finally, if you just want to force all the data to fit within a fixed interval, you can use the <code>MinMaxScaler</code>.</p>
</section>
</section>
<section id="sec-class-probabilistic" class="level2 page-columns page-full" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="sec-class-probabilistic"><span class="header-section-number">3.5</span> Probabilistic interpretation</h2>
<p>Both kNN and decision trees base classification on a voting procedure—for kNN, the <span class="math inline">\(k\)</span> nearest neighbors cast votes, and for a decision tree, the values at a leaf cast votes. So far, we have interpreted the voting results in a winner-takes-all sense, i.e., the class with the most votes wins. But that interpretation discards a lot of potentially valuable information.</p>
<div id="def-class-phat" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.10 </strong></span>Let <span class="math inline">\(\bfx\)</span> be a query vector in a vote-based classification method. The <strong>probability vector</strong> <span class="math inline">\(\hat{p}(\bfx)\)</span> is the vector of vote fractions received by each class.</p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_new5vjt4&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_137v0vyn" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.5" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div id="exm-class-phat" class="theorem example" data-chapter="3" type="✍️, 💻" data-description="Probabilistic classifier">
<p><span class="theorem-title"><strong>Example 3.14 </strong></span>Suppose we have trained a kNN classifier with <span class="math inline">\(k=10\)</span> for data with three classes, called A, B, and C, and that the votes at the testing points are as follows:</p>
<div id="1246c52a" class="cell" data-execution_count="56">
<div class="cell-output cell-output-display" data-execution_count="55">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>9</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>5</td>
<td>3</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>6</td>
<td>1</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2</td>
<td>0</td>
<td>8</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>5</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The values of <span class="math inline">\(\hat{p}\)</span> over the test set form a <span class="math inline">\(5\times 3\)</span> matrix: <!-- $$
[0.9,0,0.1],\,[0.3,0.3,0.4],\,[0.6,0.1,0.3],\,[0.2,0,0.8],\,[0.4,0.5,0.1]. 
$$ --></p>
<div id="5e402b36" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> np.array( [</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.9</span>, <span class="dv">0</span>, <span class="fl">0.1</span>],</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>],</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.6</span>, <span class="fl">0.1</span>, <span class="fl">0.3</span>],</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.2</span>, <span class="dv">0</span>, <span class="fl">0.8</span>],</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>]</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    ] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>It’s natural to interpret <span class="math inline">\(\hat{p}\)</span> as predicting the probability of each label at any query point, since the values are nonnegative and sum to 100%. Given <span class="math inline">\(\hat{p}\)</span>, we can still output a predicted class; it’s just that we also get additional information about how the prediction was made.</p>
<div id="exm-class-prob" class="theorem example" data-chapter="3" type="💻" data-description="Probabilistic classifier for the penguins dataset">
<p><span class="theorem-title"><strong>Example 3.15 </strong></span>Consider the penguin species classification problem:</p>
<div id="97032eb5" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>penguins <span class="op">=</span> sns.load_dataset(<span class="st">"penguins"</span>).dropna()</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Select only numeric columns for features:</span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> penguins.loc[:, penguins.dtypes<span class="op">==</span><span class="st">"float64"</span>]  </span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> penguins[<span class="st">"species"</span>].astype(<span class="st">"category"</span>)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>    X, y,</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">5</span></span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can train a kNN classifier and then retrieve the probabilities via <code>predict_proba</code>:</p>
<div id="b87f10b0" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> knn.predict_proba(X_test)</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>p_hat[:<span class="dv">6</span>,:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>array([[0.8, 0.2, 0. ],
       [0.8, 0.2, 0. ],
       [0. , 0. , 1. ],
       [0. , 0. , 1. ],
       [0.8, 0.2, 0. ],
       [0.6, 0.4, 0. ]])</code></pre>
</div>
</div>
<p>From the output above we see that, for example, while the third and fourth test cases led to unanimous votes for <em>Gentoo</em>, the sixth case is deemed <em>Adelie</em> in a 3–2 squeaker (or is it a squawker?):</p>
<div id="784e1aba" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>yhat[:<span class="dv">6</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>array(['Adelie', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Adelie'],
      dtype=object)</code></pre>
</div>
</div>
</div>
<section id="roc-curve" class="level3 page-columns page-full" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="roc-curve"><span class="header-section-number">3.5.1</span> ROC curve</h3>
<p>In the binary label case, our assumption so far has been that a simple majority vote determines a positive outcome. But we could choose a different threshold—a supermajority, for example, if we want to reduce false positives. This way of thinking leads us to a new way to fine-tune classification methods.</p>
<div id="def-class-hits" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.11 </strong></span>Let <span class="math inline">\(\theta\)</span> be a number in the interval <span class="math inline">\([0,1]\)</span>. We say that a class <span class="math inline">\(T\)</span> <strong>hits</strong> at level <span class="math inline">\(\theta\)</span> at a query point if the fraction of votes that <span class="math inline">\(T\)</span> receives at that point is at least <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="exm-class-hits" class="theorem example" data-chapter="3" type="💻" data-description="Varying decision threshold">
<p><span class="theorem-title"><strong>Example 3.16 </strong></span>Continuing with the data in <a href="#exm-class-phat" class="quarto-xref">Example&nbsp;<span>3.14</span></a>, we find that at <span class="math inline">\(\theta=0\)</span>, everything always hits:</p>
<div id="b347ed83" class="cell" data-execution_count="61">
<div class="cell-output cell-output-display" data-execution_count="60">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>At <span class="math inline">\(\theta=0.05\)</span>, say, we lose all the cases where no votes were received:</p>
<div id="2f98694d" class="cell" data-execution_count="62">
<div class="cell-output cell-output-display" data-execution_count="61">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>At <span class="math inline">\(\theta=0.15\)</span>, we have also lost all those receiving 1 out of 10 votes:</p>
<div id="0420d16b" class="cell" data-execution_count="63">
<div class="cell-output cell-output-display" data-execution_count="62">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>By the time we get to <span class="math inline">\(\theta=0.7\)</span>, there are only two hits left:</p>
<div id="5b501552" class="cell" data-execution_count="64">
<div class="cell-output cell-output-display" data-execution_count="63">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>The probability vector <span class="math inline">\(\hat{p}(\bfx)\)</span> holds the largest possible <span class="math inline">\(\theta\)</span> values for which each class hits at <span class="math inline">\(\bfx\)</span>. Looking at it another way, <span class="math inline">\(\theta=0\)</span> represents maximum credulity—everybody’s a winner!—while <span class="math inline">\(\theta=1\)</span> represents maximum skepticism—unanimous winners only, please.</p>
<p>The <strong>ROC curve</strong> is a way to visualize the hits as a function of <span class="math inline">\(\theta\)</span> over a fixed testing set. The idea is to tally, at each value of <span class="math inline">\(\theta\)</span>, all the hits within each class that represent true positives and false positives, and present the results visually.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_zi41n611&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_qwimazfl" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Section 3.5.1" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The name of the ROC curve is a throwback to the early days of radar, when the idea was first developed.</p>
</div>
</div>
<div id="exm-class-roc-simple" class="theorem example" data-chapter="3" type="💻" data-description="ROC curve, quasi-manually">
<p><span class="theorem-title"><strong>Example 3.17 </strong></span>We continue with the data from <a href="#exm-class-phat" class="quarto-xref">Example&nbsp;<span>3.14</span></a>, but now we add ground truth to the queries:</p>
<div id="cafed535" class="cell" data-execution_count="65">
<div class="cell-output cell-output-display" data-execution_count="64">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
<th data-quarto-table-cell-role="th">truth</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>9</td>
<td>0</td>
<td>1</td>
<td>A</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>5</td>
<td>3</td>
<td>2</td>
<td>B</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>6</td>
<td>1</td>
<td>3</td>
<td>A</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2</td>
<td>0</td>
<td>8</td>
<td>C</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>5</td>
<td>1</td>
<td>A</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Let’s look at class A. At <span class="math inline">\(\theta=0.05\)</span>, class A hits in every case, giving TP=3 and FP=2. At <span class="math inline">\(\theta=0.25\)</span>, the fourth query drops out; we still have TP=3, but now FP=1. Here is the table of all the unique values of TP and FP that we can achieve as <span class="math inline">\(\theta\)</span> varies between 0 and 1:</p>
<div id="c0f35264" class="cell" data-execution_count="66">
<div class="cell-output cell-output-display" data-execution_count="65">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">theta</th>
<th data-quarto-table-cell-role="th">FP</th>
<th data-quarto-table-cell-role="th">TP</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.05</td>
<td>2</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.25</td>
<td>1</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.45</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.55</td>
<td>0</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.65</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0.95</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>In order to make a graph, we convert the raw TP and FP numbers to rates. Since there are 2 positive and 3 negative over the entire test set, we can represent the rows above as the points <span class="math display">\[
\left(\tfrac{2}{2},\tfrac{3}{3}\right), \, \left(\tfrac{1}{2},\tfrac{3}{3}\right), \, \left(\tfrac{1}{2},\tfrac{2}{3}\right), \, \left(\tfrac{0}{2},\tfrac{2}{3}\right), \, \left(\tfrac{0}{2},\tfrac{1}{3}\right)\, \left(\tfrac{0}{2},\tfrac{0}{3}\right).
\]</span> The ROC curve for class A is just connect-the-dots for these points:</p>
<div id="ddf7ed16" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">"FP rate"</span>: [<span class="dv">1</span>,<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>,<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>], <span class="st">"TP rate"</span>: [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>,<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,<span class="dv">0</span>]})</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>sns.relplot(data<span class="op">=</span>data, </span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"FP rate"</span>, y<span class="op">=</span><span class="st">"TP rate"</span>, </span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>    kind<span class="op">=</span><span class="st">"line"</span>, estimator<span class="op">=</span><span class="va">None</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-67-output-1.png" width="469" height="468"></p>
</div>
</div>
<p>As we’re about to see, the step-by-step process above is just for illustration and is completely automated in practice.</p>
</div>
<p>Unsurprisingly, <code>sklearn</code> can compute the points defining the ROC curve automatically, which greatly simplifies drawing them. In a multiclass problem with <span class="math inline">\(K\)</span> classes, there are <span class="math inline">\(K\)</span> implied binary classificiation versions of one-vs-rest, so there are <span class="math inline">\(K\)</span> curves to draw, one for the identification of each class.</p>
<div id="exm-class-roc-penguin" class="theorem example" data-chapter="3" type="💻" data-description="ROC curve for the penguins dataset">
<p><span class="theorem-title"><strong>Example 3.18 </strong></span>Continuing <a href="#exm-class-prob" class="quarto-xref">Example&nbsp;<span>3.15</span></a>, we will plot ROC curves for the three species in the penguin data:</p>
<div id="d82d0bbd" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> knn.predict_proba(X_test)</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(knn.classes_):</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>    actual <span class="op">=</span> (y_test<span class="op">==</span>label)</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>    fp, tp, theta <span class="op">=</span> roc_curve(actual,p_hat[:,i])</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>    results.extend( [(label,fp,tp) <span class="cf">for</span> fp,tp <span class="kw">in</span> <span class="bu">zip</span>(fp,tp)] )</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>roc <span class="op">=</span> pd.DataFrame( results, columns<span class="op">=</span>[<span class="st">"label"</span>,<span class="st">"FP rate"</span>,<span class="st">"TP rate"</span>] )</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>roc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">label</th>
<th data-quarto-table-cell-role="th">FP rate</th>
<th data-quarto-table-cell-role="th">TP rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Adelie</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Adelie</td>
<td>0.027027</td>
<td>0.233333</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Adelie</td>
<td>0.054054</td>
<td>0.566667</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Adelie</td>
<td>0.216216</td>
<td>0.900000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Adelie</td>
<td>0.405405</td>
<td>0.966667</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>Adelie</td>
<td>0.459459</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>Adelie</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>Chinstrap</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>Chinstrap</td>
<td>0.019231</td>
<td>0.333333</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>Chinstrap</td>
<td>0.153846</td>
<td>0.733333</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>Chinstrap</td>
<td>0.423077</td>
<td>0.933333</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>Chinstrap</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>Gentoo</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>Gentoo</td>
<td>0.000000</td>
<td>0.909091</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>Gentoo</td>
<td>0.022222</td>
<td>0.909091</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>Gentoo</td>
<td>0.022222</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>Gentoo</td>
<td>0.088889</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>Gentoo</td>
<td>0.200000</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>Gentoo</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The table above holds all of the key points on the ROC curves:</p>
<div id="3669f7e2" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>sns.relplot(data<span class="op">=</span>roc, </span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"FP rate"</span>, y<span class="op">=</span><span class="st">"TP rate"</span>, </span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"label"</span>, kind<span class="op">=</span><span class="st">"line"</span>, estimator<span class="op">=</span><span class="va">None</span></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-69-output-1.png" width="574" height="468"></p>
</div>
</div>
<p>Each curve starts in the lower left corner and ends at the upper right corner. The ideal situation is in the top left corner of the plot, corresponding to perfect recall and specificity. All of the curves explicitly show the tradeoff between recall and specificity as the decision threshold is varied. The <em>Gentoo</em> curve comes closest to the ideal.</p>
<p>If we weight neighbors’ votes inversely to their distances from the query point, then the thresholds aren’t restricted to multiples of <span class="math inline">\(\tfrac{1}{5}\)</span>:</p>
<div id="5b48c8d8" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>knnw <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>, weights<span class="op">=</span><span class="st">"distance"</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>knnw.fit(X_train, y_train)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> knnw.predict_proba(X_test)</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(knn.classes_):</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>    actual <span class="op">=</span> (y_test<span class="op">==</span>label)</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>    fp, tp, theta <span class="op">=</span> roc_curve(actual,p_hat[:,i])</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>    results.extend( [(label,fp,tp) <span class="cf">for</span> fp,tp <span class="kw">in</span> <span class="bu">zip</span>(fp,tp)] )</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>roc <span class="op">=</span> pd.DataFrame( results, columns<span class="op">=</span>[<span class="st">"label"</span>,<span class="st">"FP rate"</span>,<span class="st">"TP rate"</span>] )</span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>sns.relplot(data<span class="op">=</span>roc, </span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"FP rate"</span>, y<span class="op">=</span><span class="st">"TP rate"</span>, </span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"label"</span>, kind<span class="op">=</span><span class="st">"line"</span>, estimator<span class="op">=</span><span class="va">None</span></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-70-output-1.png" width="574" height="468"></p>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<div style="max-width:304px">
<div style="position:relative;padding-bottom:75.986842105263%">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_j0jantoa&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_6itqu4ll" width="304" height="231" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Example 3.18" style="position:absolute;top:0;left:0;width:100%;height:100%">
</iframe>
</div>
</div>
</div></div></section>
<section id="auc" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="auc"><span class="header-section-number">3.5.2</span> AUC</h3>
<p>ROC curves lead to another classification performance metric known as <strong>area under ROC curve (AUC)</strong>. Its name tells you exactly what it is, and it ranges between 0 (bad) and 1 (ideal). Unlike the other classification metrics we have encountered, AUC tries to account not just for the result of the classification at a single threshold, but over the full range from credulous to skeptical. You might think of it as grading with partial credit.</p>
<div id="exm-class-auc" class="theorem example" data-chapter="3" type="💻" data-description="Area under ROC curve">
<p><span class="theorem-title"><strong>Example 3.19 </strong></span>The AUC metric allows us to compare the standard and weighted kNN classifiers from <a href="#exm-class-roc-penguin" class="quarto-xref">Example&nbsp;<span>3.18</span></a>. Note that the function for computing them, <code>roc_auc_score</code>, requires a keyword argument when there are more than two classes, to specify “one vs.&nbsp;rest” (our usual) or “one vs.&nbsp;one” matchups.</p>
<div id="d74e314d" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> roc_auc_score(</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>    y_test, knn.predict_proba(X_test), </span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>    multi_class<span class="op">=</span><span class="st">"ovr"</span>, average<span class="op">=</span><span class="va">None</span></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>sw <span class="op">=</span> roc_auc_score(</span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>  y_test, knnw.predict_proba(X_test), </span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>  multi_class<span class="op">=</span><span class="st">"ovr"</span>, average<span class="op">=</span><span class="va">None</span></span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(</span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"standard"</span>: s, <span class="st">"weighted"</span>: sw},</span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>knn.classes_</span>
<span id="cb96-15"><a href="#cb96-15" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">standard</th>
<th data-quarto-table-cell-role="th">weighted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Adelie</td>
<td>0.903153</td>
<td>0.935586</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Chinstrap</td>
<td>0.857051</td>
<td>0.883333</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Gentoo</td>
<td>0.997980</td>
<td>0.998990</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Based on the above scores, the weighted classifier seems to be better at identifying all three species.</p>
</div>
</section>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<p>For these exercises, you may use computer help to work on a problem, but your answer should be self-contained without reference to computer output (unless stated otherwise).</p>
<div id="exr-class-dankness" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.1 </strong></span>Here is a confusion matrix for a classifier of meme dankness.</p>
<p><img src="./_media/dankness.png" class="img-fluid" width="360"></p>
<p>Considering <em>dank</em> to be the positive outcome, calculate the <strong>(a)</strong> recall, <strong>(b)</strong> precision, <strong>(c)</strong> specificity, <strong>(d)</strong> accuracy, and <strong>(e)</strong> <span class="math inline">\(F_1\)</span> score of the classifier.</p>
</div>
<div id="exr-class-flavors" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.2 </strong></span>Here is a confusion matrix for a classifier of ice cream flavors.</p>
<p><img src="./_media/flavors.png" class="img-fluid" width="500"></p>
<p><strong>(a)</strong> Calculate the recall rate for <em>chocolate</em>.</p>
<p><strong>(b)</strong> Find the precision for <em>vanilla</em>.</p>
<p><strong>(c)</strong> Find the accuracy for <em>strawberry</em>.</p>
</div>
<div id="exr-class-gini" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.3 </strong></span>Find the Gini impurity of this set: <span class="math display">\[ \{ A, B, B, C, C, C \}.\]</span></p>
</div>
<div id="exr-class-gini-bounds" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.4 </strong></span><del>Use the definition of Gini impurity to prove that it is never negative and always less than 1.</del></p>
</div>
<div id="exr-class-partition" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.5 </strong></span>Given <span class="math inline">\(x_i=i\)</span> for <span class="math inline">\(i=0,\ldots,5\)</span>, with labels <span class="math display">\[
y_1=y_5=y_6=A, \quad y_2=y_3=y_4=B,
\]</span> find an optimal partition threshold using Gini impurity.</p>
</div>
<div id="exr-class-distance" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.6 </strong></span>Using 1-norm, 2-norm, and <span class="math inline">\(\infty\)</span>-norm, find the distance between the given vectors.</p>
<p><strong>(a)</strong> <span class="math inline">\(\bfu=[2,3,0]\)</span>, <span class="math inline">\(\;\bfv=[-2,2,1]\)</span></p>
<p><strong>(b)</strong> <span class="math inline">\(\bfu=[0,1,0,1,0]\)</span>, <span class="math inline">\(\;\bfv=[1,1,1,1,1]\)</span></p>
</div>
<div id="exr-class-norm" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.7 </strong></span><strong>(a)</strong> Prove that for any <span class="math inline">\(\bfu \in \real^d\)</span>, <span class="math inline">\(\infnorm{\bfu} \le \twonorm{\bfu}\)</span>.</p>
<p><strong>(b)</strong> Prove that for any <span class="math inline">\(\bfu \in \real^d\)</span>, <span class="math inline">\(\twonorm{\bfu} \le \sqrt{d}\, \infnorm{\bfu}\)</span>.</p>
</div>
<div id="exr-class-manhattan" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.8 </strong></span>Carefully sketch the set of all points in <span class="math inline">\(\real^2\)</span> whose 1-norm distance from the origin equals 1. This is a <em>Manhattan unit circle</em>.</p>
</div>
<div id="exr-class-triangle" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.9 </strong></span>Three points in the plane lie at the vertices of an equilateral triangle. One is labeled A and the other two are B. Carefully sketch the decision boundary for <span class="math inline">\(k\)</span>-nearest neighbors with <span class="math inline">\(k=1\)</span>, using <strong>(a)</strong> the 2-norm <del>and <strong>(b)</strong> the infinity-norm.</del></p>
</div>
<div id="exr-class-ellipse" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.10 </strong></span>Define 8 points on an ellipse by <span class="math inline">\(x_k=a\cos(\theta_k)\)</span> and <span class="math inline">\(y_k=b\sin(\theta_k)\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are positive and <span class="math display">\[
\theta_1= \frac{\pi}{4}, \theta_2 = \frac{\pi}{2}, \theta_3 = \frac{3\pi}{4}, \ldots, \theta_8 = 2\pi.
\]</span> Let <span class="math inline">\(u_1,\ldots,u_8\)</span> and <span class="math inline">\(v_1,\ldots,v_8\)</span> be the z-scores of the <span class="math inline">\(x_k\)</span> and the <span class="math inline">\(y_k\)</span>, respectively. Show that the points <span class="math inline">\((u_k,v_k)\)</span> all lie on a circle centered at the origin for all <span class="math inline">\(k=1,\ldots,8\)</span>. (By extension, standardizing points into z-scores is sometimes called <em>sphereing</em> them.)</p>
</div>
<div id="exr-class-lattice-colors" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3.11 </strong></span>Here are blue/orange labels on an integer lattice.</p>
<p><img src="_media/gridlabels.png" class="img-fluid" width="360"></p>
<p>Let <span class="math inline">\(\hat{f}(x_1,x_2)\)</span> be the kNN probabilistic classifier with <span class="math inline">\(k=4\)</span>, Euclidean metric, and mean averaging that returns the probability of a blue label. In each case below, a function <span class="math inline">\(g(t)\)</span> is defined from values of <span class="math inline">\(\hat{f}\)</span> along a vertical or horizontal line. Carefully sketch a plot of <span class="math inline">\(g(t)\)</span> for <span class="math inline">\(2\le t \le 2\)</span>.</p>
<p><strong>(a)</strong> <span class="math inline">\(g(t) = \hat{f}(1.2,t)\)</span></p>
<p><strong>(b)</strong> <span class="math inline">\(g(t) = \hat{f}(t,-0.75)\)</span></p>
<p><strong>(c)</strong> <span class="math inline">\(g(t) = \hat{f}(t,1.6)\)</span></p>
<p><strong>(d)</strong> <span class="math inline">\(g(t) = \hat{f}(-0.25,t)\)</span></p>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        console.log("RESIZE");
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./stats.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Descriptive statistics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./selection.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Model selection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Data Science 1
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Toby Driscoll
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>videojs(video_shortcode_videojs_video1);</script>
<script>videojs(video_shortcode_videojs_video2);</script>




</body></html>