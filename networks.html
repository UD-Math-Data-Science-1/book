<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-99.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science 1 - 7&nbsp; Networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./clustering.html" rel="prev">
<link href="./_media/logo_small.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script> 
MathJax = {
  chtml: {
    scale: 0.92,
  }
}
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Networks</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="quarto-sidebar-header"><div class="sidebar-header-item">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="_media/logo_small.png" height="120" class="figure-img"></p>
</figure>
</div>
</div></div>
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science 1</a> 
        <div class="sidebar-tools-main">
    <a href="./Data-Science-1.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resources.html" class="sidebar-item-text sidebar-link">Resources</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./starting.html" class="sidebar-item-text sidebar-link">Getting started</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Representation of data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Descriptive statistics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Classification</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Model selection</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Clustering</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./networks.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Networks</span></a>
  </div>
</li>
    </ul>
    </div>
<div class="quarto-sidebar-footer"><div class="sidebar-footer-item">
<p>Copyright 2023 by Toby Driscoll</p>
</div></div></nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#graphs" id="toc-graphs" class="nav-link active" data-scroll-target="#graphs"><span class="toc-section-number">7.1</span>  Graphs</a>
  <ul class="collapse">
  <li><a href="#networkx" id="toc-networkx" class="nav-link" data-scroll-target="#networkx"><span class="toc-section-number">7.1.1</span>  NetworkX</a></li>
  <li><a href="#common-graph-types" id="toc-common-graph-types" class="nav-link" data-scroll-target="#common-graph-types"><span class="toc-section-number">7.1.2</span>  Common graph types</a></li>
  <li><a href="#adjacency-matrix" id="toc-adjacency-matrix" class="nav-link" data-scroll-target="#adjacency-matrix"><span class="toc-section-number">7.1.3</span>  Adjacency matrix</a></li>
  <li><a href="#importing-networks" id="toc-importing-networks" class="nav-link" data-scroll-target="#importing-networks"><span class="toc-section-number">7.1.4</span>  Importing networks</a></li>
  <li><a href="#degree-and-average-degree" id="toc-degree-and-average-degree" class="nav-link" data-scroll-target="#degree-and-average-degree"><span class="toc-section-number">7.1.5</span>  Degree and average degree</a></li>
  <li><a href="#random-graphs" id="toc-random-graphs" class="nav-link" data-scroll-target="#random-graphs"><span class="toc-section-number">7.1.6</span>  Random graphs</a></li>
  </ul></li>
  <li><a href="#clustering" id="toc-clustering" class="nav-link" data-scroll-target="#clustering"><span class="toc-section-number">7.2</span>  Clustering</a>
  <ul class="collapse">
  <li><a href="#wattsstrogatz-graphs" id="toc-wattsstrogatz-graphs" class="nav-link" data-scroll-target="#wattsstrogatz-graphs"><span class="toc-section-number">7.2.1</span>  Watts–Strogatz graphs</a></li>
  </ul></li>
  <li><a href="#distance" id="toc-distance" class="nav-link" data-scroll-target="#distance"><span class="toc-section-number">7.3</span>  Distance</a>
  <ul class="collapse">
  <li><a href="#er-graphs" id="toc-er-graphs" class="nav-link" data-scroll-target="#er-graphs"><span class="toc-section-number">7.3.1</span>  ER graphs</a></li>
  <li><a href="#wattsstrogatz-graphs-1" id="toc-wattsstrogatz-graphs-1" class="nav-link" data-scroll-target="#wattsstrogatz-graphs-1"><span class="toc-section-number">7.3.2</span>  Watts–Strogatz graphs</a></li>
  <li><a href="#twitch-network" id="toc-twitch-network" class="nav-link" data-scroll-target="#twitch-network"><span class="toc-section-number">7.3.3</span>  Twitch network</a></li>
  </ul></li>
  <li><a href="#degree-distributions" id="toc-degree-distributions" class="nav-link" data-scroll-target="#degree-distributions"><span class="toc-section-number">7.4</span>  Degree distributions</a>
  <ul class="collapse">
  <li><a href="#power-law-distribution" id="toc-power-law-distribution" class="nav-link" data-scroll-target="#power-law-distribution"><span class="toc-section-number">7.4.1</span>  Power-law distribution</a></li>
  <li><a href="#barabásialbert-graphs" id="toc-barabásialbert-graphs" class="nav-link" data-scroll-target="#barabásialbert-graphs"><span class="toc-section-number">7.4.2</span>  Barabási–Albert graphs</a></li>
  </ul></li>
  <li><a href="#centrality" id="toc-centrality" class="nav-link" data-scroll-target="#centrality"><span class="toc-section-number">7.5</span>  Centrality</a>
  <ul class="collapse">
  <li><a href="#betweenness-centrality" id="toc-betweenness-centrality" class="nav-link" data-scroll-target="#betweenness-centrality"><span class="toc-section-number">7.5.1</span>  Betweenness centrality</a></li>
  <li><a href="#eigenvector-centrality" id="toc-eigenvector-centrality" class="nav-link" data-scroll-target="#eigenvector-centrality"><span class="toc-section-number">7.5.2</span>  Eigenvector centrality</a></li>
  <li><a href="#comparison" id="toc-comparison" class="nav-link" data-scroll-target="#comparison"><span class="toc-section-number">7.5.3</span>  Comparison</a></li>
  <li><a href="#power-law-example" id="toc-power-law-example" class="nav-link" data-scroll-target="#power-law-example"><span class="toc-section-number">7.5.4</span>  Power-law example</a></li>
  <li><a href="#friendship-paradox" id="toc-friendship-paradox" class="nav-link" data-scroll-target="#friendship-paradox"><span class="toc-section-number">7.5.5</span>  Friendship paradox</a></li>
  </ul></li>
  <li><a href="#communities" id="toc-communities" class="nav-link" data-scroll-target="#communities"><span class="toc-section-number">7.6</span>  Communities</a>
  <ul class="collapse">
  <li><a href="#simulating-the-random-walk" id="toc-simulating-the-random-walk" class="nav-link" data-scroll-target="#simulating-the-random-walk"><span class="toc-section-number">7.6.1</span>  Simulating the random walk</a></li>
  <li><a href="#label-propagation" id="toc-label-propagation" class="nav-link" data-scroll-target="#label-propagation"><span class="toc-section-number">7.6.2</span>  Label propagation</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Networks</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="hidden">
<p><span class="math display">\[
    \newcommand{\float}{\mathbb{F}}
    \newcommand{\real}{\mathbb{R}}
    \newcommand{\complex}{\mathbb{C}}
    \newcommand{\nat}{\mathbb{N}}
    \newcommand{\integer}{\mathbb{Z}}
    \newcommand{\bfa}{\mathbf{a}}
    \newcommand{\bfe}{\mathbf{e}}
    \newcommand{\bfh}{\mathbf{h}}
    \newcommand{\bfp}{\mathbf{p}}
    \newcommand{\bfq}{\mathbf{q}}
    \newcommand{\bfu}{\mathbf{u}}
    \newcommand{\bfv}{\mathbf{v}}
    \newcommand{\bfw}{\mathbf{w}}
    \newcommand{\bfx}{\mathbf{x}}
    \newcommand{\bfy}{\mathbf{y}}
    \newcommand{\bfz}{\mathbf{z}}
    \newcommand{\bfA}{\mathbf{A}}
    \newcommand{\bfW}{\mathbf{W}}
    \newcommand{\bfX}{\mathbf{X}}
    \newcommand{\bfzero}{\boldsymbol{0}}
    \newcommand{\bfmu}{\boldsymbol{\mu}}
    \newcommand{\TP}{\text{TP}}
    \newcommand{\TN}{\text{TN}}
    \newcommand{\FP}{\text{FP}}
    \newcommand{\FN}{\text{FN}}
    \newcommand{\rmn}[2]{\mathbb{R}^{#1 \times #2}}
    \newcommand{\dd}[2]{\frac{d #1}{d #2}}
    \newcommand{\pp}[2]{\frac{\partial #1}{\partial #2}}
    \newcommand{\norm}[1]{\left\lVert \mathstrut #1 \right\rVert}
    \newcommand{\abs}[1]{\left\lvert \mathstrut #1 \right\rvert}
    \newcommand{\twonorm}[1]{\norm{#1}_2}
    \newcommand{\onenorm}[1]{\norm{#1}_1}
    \newcommand{\infnorm}[1]{\norm{#1}_\infty}
    \newcommand{\innerprod}[2]{\langle #1,#2 \rangle}
    \newcommand{\pr}[1]{^{(#1)}}
    \newcommand{\diag}{\operatorname{diag}}
    \newcommand{\sign}{\operatorname{sign}}
    \newcommand{\dist}{\operatorname{dist}}
    \newcommand{\simil}{\operatorname{sim}}
    \newcommand{\ee}{\times 10^}
    \newcommand{\floor}[1]{\lfloor#1\rfloor}
    \newcommand{\argmin}{\operatorname{argmin}}
    \newcommand{\E}[1]{\operatorname{\mathbb{E}}\left[\mathstrut #1\right]}
    \newcommand{\Cov}{\operatorname{Cov}}
    \newcommand{\logit}{\operatorname{logit}}
\]</span></p>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> default_rng</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> default_rng</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Many phenomena have a natural network structure. Obvious examples are social networks, transportation networks, and the Web, but other examples include cellular protein interactions, scientific citations, ecological predation, and many others.</p>
<section id="graphs" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="graphs"><span class="header-section-number">7.1</span> Graphs</h2>
<p>In mathematics, a network is represented as a <strong>graph</strong>. A graph is a collection of <strong>nodes</strong> (also called <em>vertices</em>) and <strong>edges</strong> that connect pairs of nodes. A basic distinction in graph theory is between an <strong>undirected graph</strong>, in which the edge <span class="math inline">\((a,b)\)</span> is identical to <span class="math inline">\((b,a)\)</span>, and a <strong>directed graph</strong> or <strong>digraph</strong>, in which <span class="math inline">\((a,b)\)</span> and <span class="math inline">\((b,a)\)</span> are different potential edges. In either type of graph, each edge might be labeled with a numerical value, which results in a <strong>weighted graph</strong>.</p>
<p>Undirected, unweighted graphs will give us plenty to handle, and we will not seek to go beyond them. We also will not consider graphs that allow a node to link to itself.</p>
<section id="networkx" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="networkx"><span class="header-section-number">7.1.1</span> NetworkX</h3>
<p>We will use the NetworkX package to work with graphs.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>One way to create a graph is from a list of edges.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>star <span class="op">=</span> nx.Graph( [ (<span class="dv">1</span>,<span class="dv">2</span>),(<span class="dv">1</span>,<span class="dv">3</span>),(<span class="dv">1</span>,<span class="dv">4</span>),(<span class="dv">1</span>,<span class="dv">5</span>),(<span class="dv">1</span>,<span class="dv">6</span>) ] )</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>nx.draw(star, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">"lightblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-4-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>Another way to create a graph is to give the start and end nodes of the edges as columns in a data frame.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>network <span class="op">=</span> pd.DataFrame( {<span class="st">'from'</span>: [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>], <span class="st">'to'</span>: [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">1</span>]} )</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(network)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>H <span class="op">=</span> nx.from_pandas_edgelist(network, <span class="st">'from'</span>, <span class="st">'to'</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>nx.draw(H, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">"lightblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   from  to
0     1   2
1     2   3
2     3   4
3     4   5
4     5   6
5     6   1</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-5-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>We can conversely deconstruct a graph object into its nodes and edges. The results have special types that may need to be converted into sets, lists, or other objects.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Nodes as a list:"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="bu">list</span>(star.nodes) )</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Nodes as an Index:"</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( pd.Index(star.nodes) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Nodes as a list:
[1, 2, 3, 4, 5, 6]

Nodes as an Index:
Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')</code></pre>
</div>
</div>
<p>It’s also easy to find out which nodes are <strong>adjacent</strong> to a given node, i.e., connected to it by an edge. The result is that node’s list of <strong>neighbors</strong>.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Neighbors of node 3 in graph H:"</span>, <span class="bu">list</span>(H[<span class="dv">3</span>]) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Neighbors of node 3 in graph H: [2, 4]</code></pre>
</div>
</div>
</section>
<section id="common-graph-types" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="common-graph-types"><span class="header-section-number">7.1.2</span> Common graph types</h3>
<p>There are functions that generate different well-studied types of graphs. The first graph constructed above is a <strong>star graph</strong>, and the graph <code>H</code> above is a <strong>cycle graph</strong>.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>nx.draw(nx.cycle_graph(<span class="dv">9</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-8-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>A cross between the star and the cycle is a <strong>wheel graph</strong>.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>nx.draw(nx.wheel_graph(<span class="dv">9</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-9-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>A <strong>complete graph</strong> is one that has every possible edge.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>K5 <span class="op">=</span> nx.complete_graph(<span class="dv">5</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"5 nodes,"</span>, nx.number_of_edges(K5), <span class="st">"edges"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>nx.draw(K5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5 nodes, 10 edges</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-10-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>In a graph on <span class="math inline">\(n\)</span> nodes, there are</p>
<p><span class="math display">\[
\binom{n}{2} = \frac{n!}{(n-2)!2!} = \frac{n(n-1)}{2}
\]</span></p>
<p>unique pairs of distinct nodes. Hence, there are <span class="math inline">\(\binom{n}{2}\)</span> edges in the undirected complete graph on <span class="math inline">\(n\)</span> nodes.</p>
<p>A <strong>lattice graph</strong> has a regular structure, like graph paper.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>lat <span class="op">=</span> nx.grid_graph( (<span class="dv">5</span>,<span class="dv">4</span>) )</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lat.number_of_nodes(), <span class="st">"nodes,"</span>, lat.number_of_edges(), <span class="st">"edges"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>nx.draw(lat, node_size<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>20 nodes, 31 edges</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-11-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>In an <span class="math inline">\(m\times n\)</span> lattice graph, there are <span class="math inline">\(m-1\)</span> edges in one direction repeated <span class="math inline">\(n\)</span> times, plus <span class="math inline">\(n-1\)</span> edges in the other direction, repeated <span class="math inline">\(m\)</span> times. Thus there are</p>
<p><span class="math display">\[
(m-1)n + (n-1)m = 2mn-(m+n)
\]</span></p>
<p>edges altogether.</p>
<p>There are different ways to draw a particular graph in the plane, as determined by the positions of the nodes. The default is to imagine that the edges are springs pulling on the nodes. But there are alternatives that may be useful at times.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>nx.draw_circular(lat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-12-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>As you can see, it’s not easy to tell how similar two graphs are by comparing renderings of them.</p>
</section>
<section id="adjacency-matrix" class="level3" data-number="7.1.3">
<h3 data-number="7.1.3" class="anchored" data-anchor-id="adjacency-matrix"><span class="header-section-number">7.1.3</span> Adjacency matrix</h3>
<p>Every graph can be associated with an <strong>adjacency matrix</strong>. Suppose the nodes are numbered from <span class="math inline">\(0\)</span> to <span class="math inline">\(n-1\)</span>. The adjacency matrix is <span class="math inline">\(n\times n\)</span> and has a 1 at position <span class="math inline">\((i,j)\)</span> if node <span class="math inline">\(i\)</span> and node <span class="math inline">\(j\)</span> are adjacent, and a 0 otherwise.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> nx.adjacency_matrix(star)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>A</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>&lt;6x6 sparse matrix of type '&lt;class 'numpy.int64'&gt;'
    with 10 stored elements in Compressed Sparse Row format&gt;</code></pre>
</div>
</div>
<p>The matrix <code>A</code> is not stored in the format we have been used to. In a large network we would expect most of its entries to be zero, so it makes more sense to store it as a <em>sparse matrix</em>, where we keep track of only the nonzero entries.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (0, 1)    1
  (0, 2)    1
  (0, 3)    1
  (0, 4)    1
  (0, 5)    1
  (1, 0)    1
  (2, 0)    1
  (3, 0)    1
  (4, 0)    1
  (5, 0)    1</code></pre>
</div>
</div>
<p>We can easily convert <code>A</code> to a standard array, if it is not too large to fit in memory.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>A.toarray()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>array([[0, 1, 1, 1, 1, 1],
       [1, 0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0]])</code></pre>
</div>
</div>
<p>In an undirected graph, we have <span class="math inline">\(A_{ij}=A_{ji}\)</span> everywhere, and we say that <span class="math inline">\(A\)</span> is <em>symmetric</em>.</p>
</section>
<section id="importing-networks" class="level3" data-number="7.1.4">
<h3 data-number="7.1.4" class="anchored" data-anchor-id="importing-networks"><span class="header-section-number">7.1.4</span> Importing networks</h3>
<p>There are many ways to read graphs from (and write them to) files. For example, here is a friend network among Twitch users.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>twitch <span class="op">=</span> nx.read_edgelist(<span class="st">"musae_edges.csv"</span>, delimiter<span class="op">=</span><span class="st">','</span>, nodetype<span class="op">=</span><span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The file just imported has a pair of nodes representing one edge on each line. The nodes can have any names at all; by default they are interpreted as strings, which we overrode above to get integer node labels.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Twitch network has"</span>, </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    twitch.number_of_nodes(), </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"nodes and"</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    twitch.number_of_edges(),</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"edges"</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Twitch network has 7126 nodes and 35324 edges</code></pre>
</div>
</div>
<p>This graph is difficult to draw in its entirety. We can zoom in on a subset by selecting a node and its <strong>ego graph</strong>, which includes its neighbors along with all edges between the captured nodes.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>ego <span class="op">=</span> nx.ego_graph(twitch, <span class="dv">400</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>nx.draw(ego, with_labels<span class="op">=</span><span class="va">True</span>, node_size<span class="op">=</span><span class="dv">800</span>, node_color<span class="op">=</span><span class="st">"yellow"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-18-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>Notice that the nodes of the ego network have the same labels as they did in the graph that it was taken from. We can widen the ego graph to include the ego graphs of all the neighbors:</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>big_ego <span class="op">=</span> nx.ego_graph(twitch, <span class="dv">400</span>, radius<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(big_ego.number_of_nodes(), <span class="st">"nodes and"</span>, </span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    big_ego.number_of_edges(), <span class="st">"edges"</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(big_ego, iterations<span class="op">=</span><span class="dv">60</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>nx.draw(big_ego, </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    pos<span class="op">=</span>pos, width<span class="op">=</span><span class="fl">0.2</span>, node_size<span class="op">=</span><span class="dv">10</span>, node_color<span class="op">=</span><span class="st">"purple"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>528 nodes and 1567 edges</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-19-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>The reason for the two-step process in making the drawing above is that computing the node positions via springs takes a hidden computational iteration. By calling that iteration explicitly, we were able to stop it early and save time.</p>
</section>
<section id="degree-and-average-degree" class="level3" data-number="7.1.5">
<h3 data-number="7.1.5" class="anchored" data-anchor-id="degree-and-average-degree"><span class="header-section-number">7.1.5</span> Degree and average degree</h3>
<p>The <strong>degree</strong> of a node is the number of edges that have the node as an endpoint. Equivalently, it is the number of nodes in its ego graph, minus the original node itself. The <strong>average degree</strong> of a graph is the mean of the degrees of all of its nodes.</p>
<p>The <code>degree</code> property of a graph gives a dictionary-style object of all nodes with their degrees.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>ego.degree</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>DegreeView({897: 2, 400: 9, 5394: 2, 3379: 3, 4406: 1, 5079: 1, 6136: 2, 5049: 1, 6107: 1, 639: 2})</code></pre>
</div>
</div>
<p>The result here can be a bit awkward to work with; it’s actually a <em>generator</em> of a list, rather than the list itself. (This “lazy” attitude is useful when dealing with very large networks.) So, for instance, we can collect it into a list of ordered tuples:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(ego.degree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>[(897, 2),
 (400, 9),
 (5394, 2),
 (3379, 3),
 (4406, 1),
 (5079, 1),
 (6136, 2),
 (5049, 1),
 (6107, 1),
 (639, 2)]</code></pre>
</div>
</div>
<p>It can be convenient to use a series or frame to keep track of quantities like degree that are associated with nodes.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>nodes <span class="op">=</span> pd.Index(ego.nodes)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>degrees <span class="op">=</span> pd.Series(<span class="bu">dict</span>(ego.degree), index<span class="op">=</span>nodes)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"average degree of ego graph:"</span>, degrees.mean())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average degree of ego graph: 2.4</code></pre>
</div>
</div>
<p>There’s a much easier way to compute this particular quantity, however. If we sum the degrees of all the nodes in a graph, we must get twice the number of edges in the graph. For <span class="math inline">\(n\)</span> nodes and <span class="math inline">\(e\)</span> edges, the average degree is therefore <span class="math inline">\(2m/n\)</span>.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> average_degree(g):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span><span class="op">*</span>g.number_of_edges() <span class="op">/</span> g.number_of_nodes()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"average degree of Twitch network:"</span>, average_degree(twitch))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average degree of Twitch network: 9.914117316867808</code></pre>
</div>
</div>
</section>
<section id="random-graphs" class="level3" data-number="7.1.6">
<h3 data-number="7.1.6" class="anchored" data-anchor-id="random-graphs"><span class="header-section-number">7.1.6</span> Random graphs</h3>
<p>One way of understanding a real-world network is by comparing it to ones that are constructed randomly, but according to relatively simple rules. The idea is that if the real network behaves similarly to members of some random family, then perhaps it is constructed according to similar principles.</p>
<p>An <strong>Erdős-Rényi graph</strong> (ER graph) includes each individual possible edge with a fixed probability <span class="math inline">\(p\)</span>. That is, if you have a weighted coin that comes up heads (100p)% of the time, then you toss the coin for each possible pair of vertices and include their edge if it is heads.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>n,p <span class="op">=</span> <span class="dv">50</span>,<span class="fl">0.08</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>ER <span class="op">=</span> nx.erdos_renyi_graph(n,p,seed<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ER.number_of_nodes(),<span class="st">"nodes,"</span>,ER.number_of_edges(),<span class="st">"edges"</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>nx.draw_circular(ER,node_size<span class="op">=</span><span class="dv">50</span>,edge_color<span class="op">=</span><span class="st">"gray"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>50 nodes, 91 edges</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-24-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>Since there are <span class="math inline">\(\binom{n}{2}\)</span> unique pairs among <span class="math inline">\(n\)</span> nodes, the mean number of edges in an ER graph is</p>
<p><span class="math display">\[
p\binom{n}{2} = \frac{pn(n-1)}{2}.
\]</span></p>
<p>This fact is usually stated in terms of the average node degree, <span class="math inline">\(\bar{k}\)</span>:</p>
<p><span class="math display">\[
E[\bar{k}] = \frac{1}{n} pn(n-1) = p(n-1).
\]</span></p>
<p>There are two senses of “average” going on here: in each graph instance, you find the average degree, then you take the average (expectation, <span class="math inline">\(E[\cdot]\)</span>) over all random instances. Here is the distribution of <span class="math inline">\(\bar{k}\)</span> over 10000 instances when its expected value is <span class="math inline">\(4.0\)</span>:</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>n,p <span class="op">=</span> <span class="dv">41</span>,<span class="fl">0.1</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>kbar <span class="op">=</span> []</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    ER <span class="op">=</span> nx.erdos_renyi_graph(n,p,seed<span class="op">=</span><span class="bu">iter</span><span class="op">+</span><span class="dv">1001</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    kbar.append(average_degree(ER))</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>sns.displot(x<span class="op">=</span>kbar,bins<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-25-output-1.png" width="469" height="469"></p>
</div>
</div>
</section>
</section>
<section id="clustering" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="clustering"><span class="header-section-number">7.2</span> Clustering</h2>
<div class="callout callout-style-default callout-note callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The term <em>clustering</em> has a meaning for network analysis that has virtually nothing to do with <em>clustering</em> of numerical data.</p>
</div>
</div>
<p>In your social networks, your friends are probably more likely to be friends with each other than pure randomness would imply. There are various ways to quantify this precisely, but one of the easiest is the <strong>local clustering coefficient</strong>, defined for a node <span class="math inline">\(i\)</span> as</p>
<p><span class="math display">\[
C(i) = \frac{ 2 T(i) }{d_i(d_i-1)}.
\]</span></p>
<p>In this formula, <span class="math inline">\(d_i\)</span> is the degree of the node and <span class="math inline">\(T(i)\)</span> is the number of edges between node <span class="math inline">\(i\)</span>’s neighbors. If <span class="math inline">\(d_i=0\)</span> or <span class="math inline">\(d_i=1\)</span>, we set <span class="math inline">\(C(i)=0\)</span>.</p>
<p>Equivalently, <span class="math inline">\(T(i)\)</span> is the number of triangles in the graph that pass through node <span class="math inline">\(i\)</span>. Because the subgraph of the neighbors has</p>
<p><span class="math display">\[
\binom{d_i}{2}
\]</span></p>
<p>possible edges, the value of <span class="math inline">\(C(i)\)</span> is between 0 and 1.</p>
<p>Here is a wheel graph to help us explore a bit:</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> nx.wheel_graph(<span class="dv">7</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>nx.draw(W,with_labels<span class="op">=</span><span class="va">True</span>,node_color<span class="op">=</span><span class="st">"lightblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-26-output-1.png" width="691" height="499"></p>
</div>
</div>
<div id="exm-networks-cluster-small-world" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.1 </strong></span>Let’s find the clustering coefficient for each node in the wheel graph drawn above.</p>
<p>Node 0 in this graph is adjacent to 6 other nodes, and there are 6 triangles passing through it. Thus, its clustering coefficient is</p>
<p><span class="math display">\[
C(0) = \frac{6}{6 \cdot 5 / 2} = \frac{2}{5}.
\]</span></p>
<p>Every other node has 3 friends and 2 triangles, so they each have</p>
<p><span class="math display">\[
C(i) = \frac{2}{3 \cdot 2 / 2} = \frac{2}{3}, \quad i\neq 0.
\]</span></p>
</div>
<p>In NetworkX, we can manually count the number of edges among neighbors of node 0 by examining the ego subgraph.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>    nbrhood <span class="op">=</span> W.subgraph(W[<span class="dv">0</span>])  <span class="co"># does not include node 0 itself</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(nbrhood.number_of_edges(), <span class="st">"edges among neighbors of node 0"</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    nx.draw(nbrhood, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">"pink"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>6 edges among neighbors of node 0</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-27-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>More directly, the <code>clustering</code> function in NetworkX computes <span class="math inline">\(C(i)\)</span> for any single node, or for all the nodes in a graph.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"node 0 clustering ="</span>, nx.clustering(W,<span class="dv">0</span>))</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">clustering at each node:"</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( pd.Series(nx.clustering(W), index<span class="op">=</span>W.nodes) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>node 0 clustering = 0.4

clustering at each node:
0    0.400000
1    0.666667
2    0.666667
3    0.666667
4    0.666667
5    0.666667
6    0.666667
dtype: float64</code></pre>
</div>
</div>
<p>In addition, the <code>average_clustering</code> function will take the average over all nodes of the local clustering values.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"average clustering ="</span>, nx.average_clustering(W))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average clustering = 0.6285714285714284</code></pre>
</div>
</div>
<div id="exm-networks-cluster-er" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.2 </strong></span>Let’s compute average clustering within multiple ER random graphs.</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>n,p <span class="op">=</span> <span class="dv">121</span>,<span class="dv">1</span><span class="op">/</span><span class="dv">20</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">400</span>):</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    ER <span class="op">=</span> nx.erdos_renyi_graph(n, p, seed<span class="op">=</span><span class="bu">iter</span><span class="op">+</span><span class="dv">5000</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>    results.append( nx.average_clustering(ER) )</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>sns.displot(x<span class="op">=</span>results)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-30-output-1.png" width="469" height="469"></p>
</div>
</div>
<p>The distribution above can’t be normal, because there are hard bounds at 0 and 1, but it looks similar to a normal distribution. The peak is at the value of <span class="math inline">\(p\)</span> used in the simulation, which is not a coincidence.</p>
<div id="thm-networks-clustering-er" class="theorem">
<p><span class="theorem-title"><strong>Theorem 7.1 </strong></span>The expected value of the average clustering in ER graphs of type <span class="math inline">\((n,p)\)</span> is <span class="math inline">\(p\)</span>.</p>
</div>
<p>A formal proof of this theorem is largely superfluous; considering that each edge in the graph has a probability <span class="math inline">\(p\)</span> of inclusion, that is also the expected fraction of edges that appear within the neighborhood subgraph of any node.</p>
</div>
<div id="exm-networks-cluster-twitch" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.3 </strong></span>Let’s examine clustering within the Twitch network.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>twitch <span class="op">=</span> nx.read_edgelist(<span class="st">"musae_edges.csv"</span>, delimiter<span class="op">=</span><span class="st">','</span>, nodetype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>n,e <span class="op">=</span> twitch.number_of_nodes(), twitch.number_of_edges()</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>kbar <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>e<span class="op">/</span>n</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n, <span class="st">"nodes and"</span>, e, <span class="st">"edges"</span>)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"average degree is </span><span class="sc">{</span>kbar<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>7126 nodes and 35324 edges
average degree is 9.914</code></pre>
</div>
</div>
<p>Computing the distances between all pairs of nodes in this graph would take a rather long time, so we will estimate the average distance by sampling.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>cluster <span class="op">=</span> pd.Series(nx.clustering(twitch),index<span class="op">=</span>twitch.nodes)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>sns.displot(data<span class="op">=</span>cluster)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-32-output-1.png" width="469" height="469"></p>
</div>
</div>
<p>The average clustering coefficient is</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"average Twitch clustering:"</span>, cluster.mean() )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average Twitch clustering: 0.1309282190147198</code></pre>
</div>
</div>
<p>How does this value compare to an ER graph? If we set the number of nodes and average degree to be the same, then the expected average clustering for ER graphs is <span class="math inline">\(p=\bar{k}/(n-1)\)</span>:</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"average equivalent ER clustering:"</span>, kbar<span class="op">/</span>(n<span class="op">-</span><span class="dv">1</span>) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average equivalent ER clustering: 0.0013914550620165345</code></pre>
</div>
</div>
<p>This is too small by a factor of 100! Clearly, the Twitch graph is not equivalent to a random graph in the sense of ER. From a sociological perspective, of course, this is a “no duh” conclusion.</p>
</div>
<section id="wattsstrogatz-graphs" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="wattsstrogatz-graphs"><span class="header-section-number">7.2.1</span> Watts–Strogatz graphs</h3>
<p>A <strong>Watts–Strogatz graph</strong> (WS graph) tries to model the small-world phenomenon. A WS graph has three parameters: <span class="math inline">\(n\)</span>, an even integer <span class="math inline">\(k\)</span>, and a probability <span class="math inline">\(q\)</span>.</p>
<p>Imagine <span class="math inline">\(n\)</span> nodes arranged in a circle. Connect each node with an edge to each of its <span class="math inline">\(k/2\)</span> left neighbors and <span class="math inline">\(k/2\)</span> right neighbors. Now we “rewire” some of the edges by visiting each node <span class="math inline">\(i\)</span> in turn. For each edge from <span class="math inline">\(i\)</span> to a neighbor, with probability <span class="math inline">\(q\)</span> replace it with an edge between <span class="math inline">\(i\)</span> and a node chosen at random from all the nodes <span class="math inline">\(i\)</span> is not currently connected to. The idea is to start with tight-knit, overlapping communities, and randomly toss in some far-flung links.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>WS <span class="op">=</span> nx.watts_strogatz_graph(<span class="dv">40</span>, <span class="dv">6</span>, <span class="fl">0.15</span>, seed<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>nx.draw_circular(WS, node_size<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-35-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>By the nature of the construction, the initial state of the network (before the rewiring phase) is highly clustered. Thus, if <span class="math inline">\(q\)</span> is close to zero, the final graph will retain much of this initial clustering.</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>n, k <span class="op">=</span> <span class="dv">60</span>, <span class="dv">6</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> q <span class="kw">in</span> np.arange(<span class="fl">0.05</span>, <span class="fl">1.05</span>, <span class="fl">0.05</span>):</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>        WS <span class="op">=</span> nx.watts_strogatz_graph(n, k, q, seed<span class="op">=</span>seed)</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>        results.append( (q, nx.average_clustering(WS)) )</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>        seed <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame( results, columns<span class="op">=</span>[<span class="st">"q"</span>, <span class="st">"mean clustering"</span>] )</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean clustering in WS graphs on 60 nodes:"</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>sns.relplot(data<span class="op">=</span>results,</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"q"</span>, y<span class="op">=</span><span class="st">"mean clustering"</span>,</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    kind<span class="op">=</span><span class="st">"line"</span></span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean clustering in WS graphs on 60 nodes:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-36-output-2.png" width="469" height="468"></p>
</div>
</div>
<p>Let’s scale the experiment above up to the size of the Twitch network. Conveniently, the average degree is nearly 10, which is the value we will use in the WS construction. To save computation time, we will use just one WS realization at each value of <span class="math inline">\(q\)</span>.</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">99999</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>n, k <span class="op">=</span> twitch.number_of_nodes(), <span class="dv">10</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> q <span class="kw">in</span> np.arange(<span class="fl">0.15</span>, <span class="fl">0.61</span>, <span class="fl">0.05</span>):</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    WS <span class="op">=</span> nx.watts_strogatz_graph(n, k, q, seed<span class="op">=</span>seed)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"q = </span><span class="sc">{</span>q<span class="sc">:.2f}</span><span class="ss">, avg WS clustering = </span><span class="sc">{</span>nx<span class="sc">.</span>average_clustering(WS)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    seed <span class="op">+=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>q = 0.15, avg WS clustering = 0.4143
q = 0.20, avg WS clustering = 0.3418
q = 0.25, avg WS clustering = 0.2870</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>q = 0.30, avg WS clustering = 0.2326
q = 0.35, avg WS clustering = 0.1809
q = 0.40, avg WS clustering = 0.1470</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>q = 0.45, avg WS clustering = 0.1112
q = 0.50, avg WS clustering = 0.0851</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>q = 0.55, avg WS clustering = 0.0627
q = 0.60, avg WS clustering = 0.0424</code></pre>
</div>
</div>
<p>The mean clustering resembles the value of 0.131 for the Twitch network at around <span class="math inline">\(q=0.42\)</span>, which we verify using more realizations:</p>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">999</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>n,k,q <span class="op">=</span> twitch.number_of_nodes(),<span class="dv">10</span>,<span class="fl">0.42</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>cbar <span class="op">=</span> []</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>    WS <span class="op">=</span> nx.watts_strogatz_graph(n, k, q, seed<span class="op">=</span>seed)</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    cbar.append( nx.average_clustering(WS) )</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    seed <span class="op">+=</span> <span class="dv">10</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"avg WS clustering at q = 0.42:"</span>, np.mean(cbar) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>avg WS clustering at q = 0.42: 0.13177740621327544</code></pre>
</div>
</div>
<p>The WS construction gives a plausible way to reconstruct the clustering observed in the Twitch network. However, there are other graph properties left to examine.</p>
</section>
</section>
<section id="distance" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="distance"><span class="header-section-number">7.3</span> Distance</h2>
<p>The <em>small-world phenomenon</em> is, broadly speaking, the observation that any two people in a group can be connected by a surprisingly short path of acquaintances. This concept appears, for instance, in the <em>Bacon number game</em>, where actors are nodes, appearing in the same movie creates an edge between them, and one tries to find the distance between Kevin Bacon and some other designated actor.</p>
<p>The <strong>distance</strong> between two nodes in a connected graph is the number of edges in the shortest path between them. For example, in a complete graph, the distance between any pair of distinct nodes is 1, since all possible pairs are connected by an edge.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>K5 <span class="op">=</span> nx.complete_graph(<span class="dv">5</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>dist <span class="op">=</span> pd.Series(nx.shortest_path_length(K5,<span class="dv">0</span>), index<span class="op">=</span>K5.nodes)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Distance from node 0:"</span>, dist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Distance from node 0: 0    0
1    1
2    1
3    1
4    1
dtype: int64</code></pre>
</div>
</div>
<p>The maximum distance over all pairs of nodes in a graph is called its <strong>diameter</strong>. Since this value depends on an extreme outlier in the distribution of distances, we often preferr to use the <strong>average distance</strong> as a measure of how difficult it is to connect two randomly selected nodes.</p>
<p>For example, here is a wheel graph:</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> nx.wheel_graph(<span class="dv">7</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>nx.draw(W, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">"lightblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-40-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>No node is more than two hops away from another (if the first hop is to node 0), so the diameter of this graph is 2. The average distance is somewhat smaller. This graph is so small that we can easily find the entire matrix of pairwise distances. The matrix is symmetric, so it’s only necessary to compute its upper triangle.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>nodes <span class="op">=</span> <span class="bu">list</span>(W.nodes)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(nodes)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> np.zeros( (n,n), dtype<span class="op">=</span><span class="bu">int</span> )</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>,n):</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>        D[i,j] <span class="op">=</span> nx.shortest_path_length(W, nodes[i], nodes[j]) </span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(D)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[0 1 1 1 1 1 1]
 [0 0 1 2 2 2 1]
 [0 0 0 1 2 2 2]
 [0 0 0 0 1 2 2]
 [0 0 0 0 0 1 2]
 [0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0]]</code></pre>
</div>
</div>
<p>To get the average distance, we can sum over all the entries and divide by <span class="math inline">\(\binom{n}{2}\)</span>:</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"average distance:"</span>, <span class="dv">2</span><span class="op">*</span>D.<span class="bu">sum</span>() <span class="op">/</span> (n<span class="op">*</span>(n<span class="op">-</span><span class="dv">1</span>)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average distance: 1.4285714285714286</code></pre>
</div>
</div>
<p>There is a convenience function for computing this average. (It becomes slow as <span class="math inline">\(n\)</span> grows, though.)</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"average distance:"</span>, nx.average_shortest_path_length(W) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average distance: 1.4285714285714286</code></pre>
</div>
</div>
<section id="er-graphs" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="er-graphs"><span class="header-section-number">7.3.1</span> ER graphs</h3>
<p>If we want to compute distances within ER random graphs, we quickly run into a problem: an ER graph may not have a path between every pair of nodes:</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">101</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">25</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>ER <span class="op">=</span> nx.erdos_renyi_graph(n, p, seed<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>nx.draw(ER, node_size<span class="op">=</span><span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-44-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>We say that such a graph is not <strong>connected</strong>. When no path exists between two nodes, the distance between them is either undefined or infinite. NetworkX will give an error if we try to compute the average distance in a disconnected graph:</p>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>nx.average_shortest_path_length(ER)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>NetworkXError: Graph is not connected.</code></pre>
</div>
</div>
<p>One way to cope with this eventuality is to decompose the graph into <strong>connected components</strong>, a disjoint separation of the nodes into connected subgraphs. We can use <code>nx.connected_components</code> to get node sets for each component.</p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>[ <span class="bu">len</span>(cc) <span class="cf">for</span> cc <span class="kw">in</span> nx.connected_components(ER) ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>[100, 1]</code></pre>
</div>
</div>
<p>The result above tells us that removing the lone unconnected node in the ER graph leaves us with a connected component. We can always get the largest component with the following idiom:</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>ER_sub <span class="op">=</span> ER.subgraph( <span class="bu">max</span>(nx.connected_components(ER), key<span class="op">=</span><span class="bu">len</span>) )</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ER_sub.number_of_nodes(), <span class="st">"nodes in largest component"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>100 nodes in largest component</code></pre>
</div>
</div>
<p>Now the average path length is a valid computation.</p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>nx.average_shortest_path_length(ER_sub)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>3.3082828282828283</code></pre>
</div>
</div>
<p>Let’s use this method to examine average distances within ER graphs of a fixed type.</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>n,p <span class="op">=</span> <span class="dv">121</span>,<span class="dv">1</span><span class="op">/</span><span class="dv">20</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>dbar <span class="op">=</span> []</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    ER <span class="op">=</span> nx.erdos_renyi_graph(n, p, seed<span class="op">=</span><span class="bu">iter</span><span class="op">+</span><span class="dv">5000</span>)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    ER_sub <span class="op">=</span> ER.subgraph( <span class="bu">max</span>(nx.connected_components(ER), key<span class="op">=</span><span class="bu">len</span>) )</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>    dbar.append( nx.average_shortest_path_length(ER_sub) )</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"average distance in the big component of ER graphs:"</span>)</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>sns.displot(x<span class="op">=</span>dbar, bins<span class="op">=</span><span class="dv">13</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>average distance in the big component of ER graphs:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-49-output-2.png" width="470" height="469"></p>
</div>
</div>
<p>The chances are good, therefore, that any message could be passed along in three hops or fewer (within the big component). In fact, theory states that as <span class="math inline">\(n\to\infty\)</span>, the mean distance in ER graphs is expected to be approximately</p>
<p><span id="eq-networks-small-world-ERdistance"><span class="math display">\[
\frac{\ln(n)}{\ln(\bar{k})}.
\tag{7.1}\]</span></span></p>
<p>For <span class="math inline">\(n=121\)</span> and <span class="math inline">\(\bar{k}=6\)</span> as in the experiment above, this value is about 2.68.</p>
</section>
<section id="wattsstrogatz-graphs-1" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="wattsstrogatz-graphs-1"><span class="header-section-number">7.3.2</span> Watts–Strogatz graphs</h3>
<p>The Watts–Strogatz model was originally proposed to demonstrate small-world networks. The initial ring-lattice structure of the construction exhibits both large clustering and large mean distance:</p>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.watts_strogatz_graph(<span class="dv">400</span>, <span class="dv">6</span>, <span class="dv">0</span>)  <span class="co"># q=0 ==&gt; initial ring lattice</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>C0 <span class="op">=</span> nx.average_clustering(G)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>L0 <span class="op">=</span> nx.average_shortest_path_length(G)</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ring lattice has average clustering </span><span class="sc">{</span>C0<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"and average shortest path length </span><span class="sc">{</span>L0<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ring lattice has average clustering 0.6000
and average shortest path length 33.75</code></pre>
</div>
</div>
<p>At the other extreme of <span class="math inline">\(p=1\)</span>, we get an ER random graph, which (at equivalent parameters) has small clustering and small average distance. The most interesting aspect of WS graphs is the transition between these extremes as <span class="math inline">\(p\)</span> varies.</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>cbar, dbar, logq <span class="op">=</span> [],[],[]</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lq <span class="kw">in</span> np.arange(<span class="op">-</span><span class="fl">3.5</span>, <span class="fl">0.01</span>, <span class="fl">0.25</span>):</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>):</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> nx.watts_strogatz_graph(<span class="dv">400</span>, <span class="dv">6</span>, <span class="dv">10</span><span class="op">**</span>lq, seed<span class="op">=</span><span class="dv">975</span><span class="op">+</span><span class="bu">iter</span>)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>        cbar.append( nx.average_clustering(G) <span class="op">/</span> C0 )</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>        dbar.append( nx.average_shortest_path_length(G) <span class="op">/</span> L0 )</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>        logq.append(lq)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame( {<span class="st">"log10(q)"</span>:logq, <span class="st">"avg clustering"</span>:cbar, <span class="st">"avg distance"</span>:dbar} )  </span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>sns.relplot(data<span class="op">=</span>pd.melt(results, id_vars<span class="op">=</span><span class="st">"log10(q)"</span>),</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>            x<span class="op">=</span><span class="st">"log10(q)"</span>, y<span class="op">=</span><span class="st">"value"</span>,</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>            hue<span class="op">=</span><span class="st">"variable"</span>, kind<span class="op">=</span><span class="st">"line"</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>            )<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-52-output-1.png" width="601" height="468"></p>
</div>
</div>
<p>The horizontal axis above is <span class="math inline">\(\log_{10}(q)\)</span>, and the vertical axis shows the average clustering and shortest path length normalized by their values at <span class="math inline">\(q=0\)</span>. Watts and Strogatz raised awareness of the fact that for quite small values of <span class="math inline">\(q\)</span>, i.e., relatively few nonlocal connections, there are networks with a large clustering coefficient and small average distance.</p>
</section>
<section id="twitch-network" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="twitch-network"><span class="header-section-number">7.3.3</span> Twitch network</h3>
<p>Let’s consider distances within the Twitch network.</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>twitch <span class="op">=</span> nx.read_edgelist(<span class="st">"musae_edges.csv"</span>, delimiter<span class="op">=</span><span class="st">','</span>, nodetype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>n, e <span class="op">=</span> twitch.number_of_nodes(), twitch.number_of_edges()</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>kbar <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>e<span class="op">/</span>n</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n, <span class="st">"nodes and"</span>, e, <span class="st">"edges"</span>)</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"average degree is </span><span class="sc">{</span>kbar<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>7126 nodes and 35324 edges
average degree is 9.914</code></pre>
</div>
</div>
<p>Computing the distances between all pairs of nodes in this graph would take a rather long time, so we will sample some pairs randomly.</p>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> default_rng(<span class="dv">1</span>)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the distance between a random pair of distinct nodes:</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pairdist(G):</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> nx.number_of_nodes(G)</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> j <span class="op">=</span> rng.integers(<span class="dv">0</span>,n)</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i<span class="op">==</span>j: j<span class="op">=</span>rng.integers(<span class="dv">0</span>,n)   <span class="co"># get distinct nodes</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nx.shortest_path_length(G,source<span class="op">=</span>i,target<span class="op">=</span>j)</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> [ pairdist(twitch) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50000</span>) ]</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pairwise distances in Twitch graph:"</span>)</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>sns.displot(x<span class="op">=</span>distances, discrete<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"estimated mean ="</span>, np.mean(distances) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Pairwise distances in Twitch graph:
estimated mean = 3.67376</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-54-output-2.png" width="469" height="469"></p>
</div>
</div>
<p>Let’s compare these results to ER graphs with the same size and average degree, i.e., with <span class="math inline">\(p=\bar{k}/(n-1)\)</span>. The theoretical estimate from above gives</p>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Comparable ER graphs expected mean distance:"</span>, np.log(n) <span class="op">/</span> np.log(kbar) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Comparable ER graphs expected mean distance: 3.8673326382368893</code></pre>
</div>
</div>
<p>The Twitch network has a slightly smaller value than this, but the numbers are comparable. However, remember that the ER graphs have a negligible clustering coefficient.</p>
<p>Next we explore Watts–Strogatz graphs with the same <span class="math inline">\(n\)</span> as the Twitch network and <span class="math inline">\(k=10\)</span> to get a similar average degree.</p>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">44044</span></span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>n, k <span class="op">=</span> twitch.number_of_nodes(), <span class="dv">10</span></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> q <span class="kw">in</span> np.arange(<span class="fl">0.1</span>, <span class="fl">0.76</span>, <span class="fl">0.05</span>):</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>        WS <span class="op">=</span> nx.watts_strogatz_graph(n, k, q, seed<span class="op">=</span>seed)</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>        dbar <span class="op">=</span> <span class="bu">sum</span>(pairdist(WS) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">60</span>))<span class="op">/</span><span class="dv">60</span></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>        results.append( (q,dbar) )</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>        seed <span class="op">+=</span> <span class="dv">7</span></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame( results, columns<span class="op">=</span>[<span class="st">"q"</span>, <span class="st">"avg distance"</span>] )</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pairwise distances in WS graphs:"</span>)</span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a>sns.relplot(data<span class="op">=</span>results, x<span class="op">=</span><span class="st">"q"</span>, y<span class="op">=</span><span class="st">"avg distance"</span>, kind<span class="op">=</span><span class="st">"line"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Pairwise distances in WS graphs:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-56-output-2.png" width="469" height="468"></p>
</div>
</div>
<p>The decrease with <span class="math inline">\(q\)</span> is less pronounced that it was for the smaller WS graphs above. In the previous section, we found that <span class="math inline">\(q=0.42\)</span> reproduces the same average clustering as in the Twitch network. That corresponds to a mean distance of about 4.5, which is a bit above the observed Twitch mean distance of 3.87, but not dramatically so. Thus, the Watts-Strogatz model could still be considered a plausible one for the Twitch network. In the next section, though, we will see that it misses badly in at least one important aspect.</p>
</section>
</section>
<section id="degree-distributions" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="degree-distributions"><span class="header-section-number">7.4</span> Degree distributions</h2>
<p>As we know, means of distributions do not always tell the entire story. For example, the distribution of the degrees of all the nodes in our Twitch network has some surprising features.</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>twitch <span class="op">=</span> nx.read_edgelist(<span class="st">"musae_edges.csv"</span>, delimiter<span class="op">=</span><span class="st">','</span>, nodetype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>twitch_degrees <span class="op">=</span> pd.Series( <span class="bu">dict</span>(twitch.degree), index<span class="op">=</span>twitch.nodes )</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>twitch_degrees.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>count    7126.000000
mean        9.914117
std        22.190263
min         1.000000
25%         2.000000
50%         5.000000
75%        11.000000
max       720.000000
dtype: float64</code></pre>
</div>
</div>
<p>Observe above that that there is a significant disparity between the mean and median values of the degree distribution, and that the standard deviation is much larger than the mean. A histogram plot confirms that the degree distribution is widely dispersed:</p>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Twitch network degree distribution:"</span>)</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>sns.displot(twitch_degrees)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Twitch network degree distribution:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-58-output-2.png" width="469" height="469"></p>
</div>
</div>
<p>A few nodes in the network have hundreds of friends:</p>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>friend_counts <span class="op">=</span> twitch_degrees.value_counts()  <span class="co"># histogram heights</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>friend_counts.sort_index(ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>720    1
691    1
465    1
378    1
352    1
336    1
316    1
278    1
272    1
254    1
dtype: int64</code></pre>
</div>
</div>
<p>These “gregarious nodes” or <em>hubs</em> are characteristic of many social and other real-world networks.</p>
<p>We can compare the above distribution to that in a collection of ER graphs with the same size and expected average degree.</p>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>n, e <span class="op">=</span> twitch.number_of_nodes(), twitch.number_of_edges()</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>kbar <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>e<span class="op">/</span>n</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> kbar<span class="op">/</span>(n<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>degrees <span class="op">=</span> []</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>    ER <span class="op">=</span> nx.erdos_renyi_graph(n, p, seed<span class="op">=</span><span class="dv">111</span><span class="op">+</span><span class="bu">iter</span>)</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>    degrees.extend( [ER.degree(i) <span class="cf">for</span> i <span class="kw">in</span> ER.nodes] )</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ER graphs degree distribution:"</span>)</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>sns.displot(degrees, discrete<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ER graphs degree distribution:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-60-output-2.png" width="469" height="469"></p>
</div>
</div>
<p>Theory proves that the plot above converges to a <em>binomial distribution</em>. This is yet another indicator that the ER model does not explain the Twitch network well. A WS graph has a similar distribution:</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>k,q <span class="op">=</span> <span class="dv">10</span>, <span class="fl">0.42</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>degrees <span class="op">=</span> []</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>    WS <span class="op">=</span> nx.watts_strogatz_graph(n, k, q, seed<span class="op">=</span><span class="dv">222</span><span class="op">+</span><span class="bu">iter</span>)</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>    degrees.extend( [WS.degree(i) <span class="cf">for</span> i <span class="kw">in</span> WS.nodes] )</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"WS graphs degree distribution:"</span>)</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>sns.displot(degrees, discrete<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>WS graphs degree distribution:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-61-output-2.png" width="470" height="469"></p>
</div>
</div>
<section id="power-law-distribution" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="power-law-distribution"><span class="header-section-number">7.4.1</span> Power-law distribution</h3>
<p>The behavior of the Twitch degree distribution gets very interesting when the axes are transformed to use log scales:</p>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> sns.displot(data<span class="op">=</span>twitch_degrees, log_scale<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>hist.axes[<span class="dv">0</span>,<span class="dv">0</span>].set_yscale(<span class="st">"log"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-62-output-1.png" width="458" height="468"></p>
</div>
</div>
<p>For degrees between 10 and several hundred, the counts lie nearly on a straight line. That is, if <span class="math inline">\(x\)</span> is degree and <span class="math inline">\(y\)</span> is the node count at that degree, then</p>
<p><span class="math display">\[
\log(y) \approx  - a\cdot \log(x) + b,
\]</span></p>
<p>i.e.,</p>
<p><span class="math display">\[
y \approx B x^{-a},
\]</span></p>
<p>for some <span class="math inline">\(a &gt; 0\)</span>. This relationship is known as a <strong>power law</strong>. Many social networks seem to follow a power-law distribution of node degrees, to some extent. (The precise extent is a subject of hot debate.)</p>
<p>Note that the decay of <span class="math inline">\(x^{-a}\)</span> to zero as <span class="math inline">\(x\to\infty\)</span> is much slower than, say, the normal distribution’s <span class="math inline">\(e^{-x^2/2}\)</span>, or even just an exponential <span class="math inline">\(e^{-cx}\)</span>. This last comparison is how a <em>heavy-tailed distribution</em> is usually defined.</p>
<p>We can get a fair estimate of the constants <span class="math inline">\(B\)</span> and <span class="math inline">\(a\)</span> in the power law by doing a least-squares fit on the logs of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. First, we need the counts:</p>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> twitch_degrees.value_counts()</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> pd.DataFrame( {<span class="st">"degree"</span>: y.index, <span class="st">"count"</span>: y.values} )</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> counts[ (counts[<span class="st">"degree"</span>] <span class="op">&gt;</span> <span class="dv">10</span>) <span class="op">&amp;</span> (counts[<span class="st">"degree"</span>] <span class="op">&lt;</span> <span class="dv">200</span>) ]<span class="op">;</span></span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>counts.head(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<div>


<table class="dataframe table table-sm table-striped" data-border="1">
<thead>
<tr class="header">
<th></th>
<th>degree</th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th>10</th>
<td>11</td>
<td>193</td>
</tr>
<tr class="even">
<th>11</th>
<td>12</td>
<td>155</td>
</tr>
<tr class="odd">
<th>12</th>
<td>13</td>
<td>131</td>
</tr>
<tr class="even">
<th>13</th>
<td>14</td>
<td>122</td>
</tr>
<tr class="odd">
<th>14</th>
<td>15</td>
<td>103</td>
</tr>
<tr class="even">
<th>15</th>
<td>17</td>
<td>83</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now we will get additional columns by log transformations. (Note: the <code>np.log</code> function is the natural logarithm.)</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>logcounts <span class="op">=</span> counts.transform(np.log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we use <code>sklearn</code> for a linear regression.</p>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>lm <span class="op">=</span> LinearRegression()</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>lm.fit(logcounts[[<span class="st">"degree"</span>]], logcounts[<span class="st">"count"</span>])</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>lm.coef_[<span class="dv">0</span>], lm.intercept_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(-1.9941272617745713, 9.7094067609447)</code></pre>
</div>
</div>
<p>The first value, which is both the slope of the line and the exponent of <span class="math inline">\(x\)</span> in the power law, is the most interesting part. It estimates that the degree counts vary as <span class="math inline">\(Bx^{-2.1}\)</span> over a wide range of degrees.</p>
</section>
<section id="barabásialbert-graphs" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="barabásialbert-graphs"><span class="header-section-number">7.4.2</span> Barabási–Albert graphs</h3>
<p>A random <strong>Barabási–Albert</strong> graph (BA graph) is constructed by starting with a small seed network and connecting one node at a time with <span class="math inline">\(m\)</span> new edges to it. Edges are added randomly, but higher probability is given to connect to nodes that already have higher degree (i.e., are more “popular”), a concept known as <em>preferential attachment</em>. Because of this rule, there is a natural tendency to develop a few hubs of high degree.</p>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>BA <span class="op">=</span> nx.barabasi_albert_graph(<span class="dv">100</span>, <span class="dv">2</span>, seed<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>BA_degrees <span class="op">=</span> pd.Series( <span class="bu">dict</span>(BA.degree), index<span class="op">=</span>BA.nodes )</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>nx.draw(BA, node_size<span class="op">=</span><span class="dv">8</span><span class="op">*</span>BA_degrees, node_color<span class="op">=</span><span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-66-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>When we match these graphs to the size and average degree of the Twitch network, a power-law distribution emerges. Since we add <span class="math inline">\(m\)</span> edges (almost) <span class="math inline">\(n\)</span> times, the expected average degree is <span class="math inline">\(2mn/n=2m\)</span>. Therefore, in the BA construction we want to choose</p>
<p><span class="math display">\[
m \approx \frac{\bar{k}}{2}.
\]</span></p>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="bu">round</span>(kbar<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>BA <span class="op">=</span> nx.barabasi_albert_graph(n, m, seed<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>BA_degrees <span class="op">=</span> pd.Series( <span class="bu">dict</span>(BA.degree), index<span class="op">=</span>BA.nodes )</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> sns.displot(data<span class="op">=</span>BA_degrees, log_scale<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>hist.axes[<span class="dv">0</span>,<span class="dv">0</span>].set_yscale(<span class="st">"log"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-67-output-1.png" width="459" height="468"></p>
</div>
</div>
<p>Theory predicts that the exponent of the power-law distribution in a BA graph is <span class="math inline">\(-3\)</span>.</p>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> BA_degrees.value_counts()</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> pd.DataFrame( {<span class="st">"degree"</span>:y.index, <span class="st">"count"</span>:y.values} )</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> counts[ (counts[<span class="st">"degree"</span>] <span class="op">&gt;</span> <span class="dv">5</span>) <span class="op">&amp;</span> (counts[<span class="st">"degree"</span>] <span class="op">&lt;</span> <span class="dv">80</span>) ]</span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a>logcounts <span class="op">=</span> counts.transform(np.log)</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a>lm.fit( logcounts[[<span class="st">"degree"</span>]], logcounts[<span class="st">"count"</span>] )</span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"exponent of power law:"</span>, lm.coef_[<span class="dv">0</span>] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>exponent of power law: -2.873136852062997</code></pre>
</div>
</div>
<p>Let’s check distances and clustering, too. As a reminder, the mean distance in the Twitch network is approximately:</p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> default_rng</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> default_rng(<span class="dv">1</span>)</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pairdist(G):</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> nx.number_of_nodes(G)</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> j <span class="op">=</span> rng.integers(<span class="dv">0</span>, n)</span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i<span class="op">==</span>j: j<span class="op">=</span>rng.integers(<span class="dv">0</span>, n)   <span class="co"># get distinct nodes</span></span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nx.shortest_path_length(G, source<span class="op">=</span>i, target<span class="op">=</span>j)</span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean distance in Twitch graph:"</span>,</span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">sum</span>(pairdist(twitch) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4000</span>)) <span class="op">/</span> <span class="dv">4000</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean distance in Twitch graph: 3.657</code></pre>
</div>
</div>
<p>Now we repeat that for some BA graphs.</p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>dbar <span class="op">=</span> []</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">911</span></span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>    BA <span class="op">=</span> nx.barabasi_albert_graph(n, m, seed<span class="op">=</span>seed)</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="bu">sum</span>(pairdist(BA) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>)) <span class="op">/</span> <span class="dv">200</span></span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a>    dbar.append(d)</span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a>    seed <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Mean distance in BA graphs:"</span>, np.mean(dbar) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean distance in BA graphs: 3.5555</code></pre>
</div>
</div>
<p>Not bad! Now, let’s check the clustering. For Twitch, we have:</p>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Mean clustering in Twitch graph:"</span>, nx.average_clustering(twitch) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean clustering in Twitch graph: 0.13092821901472096</code></pre>
</div>
</div>
<p>And for BA, we get</p>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>cbar <span class="op">=</span> []</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">59</span></span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>    BA <span class="op">=</span> nx.barabasi_albert_graph(n, m, seed<span class="op">=</span>seed)</span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>    cbar.append( nx.average_clustering(BA) )</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>    seed <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Mean clustering in BA graphs:"</span>, np.mean(cbar) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean clustering in BA graphs: 0.009219743245252128</code></pre>
</div>
</div>
<p>The BA model is our closest approach so far, but it fails to produce the close-knit neighbor subgraphs that we find in the Twitch network and the WS model.</p>
</section>
</section>
<section id="centrality" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="centrality"><span class="header-section-number">7.5</span> Centrality</h2>
<p>In some applications we might want to know which nodes of a network are the most important. For instance, we might want to find influential members of a social network, or nodes that are critical for efficient connections within the network. These traits go under the general name of <strong>centrality</strong>.</p>
<p>An easy candidate for measuring the centrality of a node is its degree. Usually this is normalized by the number of nodes in the graph and called <strong>degree centrality</strong>. While it can yield useful infortmation in some networks, it is not always a reliable measuring stick. For example, consider the following Watts–Strogatz graph:</p>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.watts_strogatz_graph(<span class="dv">60</span>, <span class="dv">2</span>, <span class="fl">.1</span>, seed<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G,seed<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>style <span class="op">=</span> <span class="bu">dict</span>(pos<span class="op">=</span>pos, edge_color<span class="op">=</span><span class="st">"gray"</span>, node_color<span class="op">=</span><span class="st">"pink"</span>, with_labels<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>nx.draw(G, <span class="op">**</span>style, node_size<span class="op">=</span><span class="dv">120</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-73-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>There is little variation in the degrees of the nodes. In fact, there are only 3 unique values of the degree centrality:</p>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>centrality <span class="op">=</span> pd.DataFrame( {<span class="st">"degree"</span>:nx.degree_centrality(G)}, index<span class="op">=</span>G.nodes )</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>sns.displot(data<span class="op">=</span>centrality, x<span class="op">=</span><span class="st">"degree"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-74-output-1.png" width="469" height="468"></p>
</div>
</div>
<p>From the drawing of the graph, however, it’s clear that (for instance) nodes 3 and 6 do not have comparable roles, despite the fact that both have degree equal to 2.</p>
<section id="betweenness-centrality" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="betweenness-centrality"><span class="header-section-number">7.5.1</span> Betweenness centrality</h3>
<p>A different way to measure centrality is to use shortest paths between nodes. Let <span class="math inline">\(\sigma(i,j)\)</span> denote the number of shortest paths between nodes <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>. This means that we count the number of unique ways to get between these nodes using the minimum possible number of edges. Let <span class="math inline">\(\sigma(i,j|k)\)</span> be the number of such paths that pass through node <span class="math inline">\(k\)</span>. Then, for a graph on <span class="math inline">\(n\)</span> nodes, the <strong>betweenness centrality</strong> of node <span class="math inline">\(k\)</span> is</p>
<p><span class="math display">\[
c_B(k) = \frac{1}{\binom{n-1}{2}}\, \displaystyle\sum_{\substack{\text{all pairs }i,j\\i\neq k,\,j\neq k}} \frac{\sigma(i,j|k)}{\sigma(i,j)}.
\]</span></p>
<p>Each term in the sum is less than or equal to 1, and the number of terms in the sum is <span class="math inline">\(\binom{n-1}{2}\)</span>, so <span class="math inline">\(0\le c_B \le 1\)</span> for any node. The definition requires an expensive computation if the number of nodes is more than a few hundred, so the <span class="math inline">\(\sigma\)</span> values are often estimated by sampling.</p>
<div id="exm-networks-between-barbell" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.4 </strong></span>We will find the betweenness centrality of the following <em>barbell graph</em>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="_media/barbell.png" class="img-fluid figure-img" width="350"></p>
<p></p><figcaption class="figure-caption">Barbell graph</figcaption><p></p>
</figure>
</div>
<p>Let’s begin with node 3, in the middle. Any path, and therefore any shortest path, between nodes 0, 1, or 2 and nodes 4, 5, or 6 must pass through node 3, so these pairings each contribute 1 to the sum. The shortest paths for pairs of nodes within the end triangles clearly do not pass through node 3. Hence</p>
<p><span class="math display">\[
c_B(3) = \frac{1}{15} \cdot (3\cdot 3) = \frac{3}{5}.
\]</span></p>
<p>Next, consider node 2. The shortest paths through this node are the ones that pair nodes 0 or 1 with nodes 3, 4, 5, or 6, so</p>
<p><span class="math display">\[
c_B(2) = \frac{1}{15} \cdot (2\cdot 4) = \frac{8}{15}.
\]</span></p>
<p>By symmetry, we get the same value for node 4.</p>
<p>All the other nodes play no role in any shortest paths. For instance, any path passing through node 0 can be replaced with a shorter one that follows the edge between nodes 1 and 2. Hence <span class="math inline">\(c_B\)</span> is zero on these nodes.</p>
</div>
<p>The <code>betweenness_centrality</code> function returns a dictionary with nodes as keys and <span class="math inline">\(c_B\)</span> as values.</p>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>centrality[<span class="st">"between"</span>] <span class="op">=</span> pd.Series(nx.betweenness_centrality(G), index<span class="op">=</span>G.nodes)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>sns.displot(data<span class="op">=</span>centrality, x<span class="op">=</span><span class="st">"between"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-75-output-1.png" width="469" height="468"></p>
</div>
</div>
<p>The distribution above shows that few nodes have a relatively high betweenness score in our graph.</p>
</section>
<section id="eigenvector-centrality" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="eigenvector-centrality"><span class="header-section-number">7.5.2</span> Eigenvector centrality</h3>
<p>A different way of distinguishing nodes of high degree is to suppose that not all links are equally valuable. By analogy with ranking sports teams, where wins over good teams should count for more than wins over bad teams, we should assign more importance to nodes that link to other important nodes.</p>
<p>We can try to turn this idea into an algorithm as follows. Suppose we initially assign uniform centrality scores <span class="math inline">\(x_1,\ldots,x_n\)</span> to all of the nodes. Now we can update the scores by looking at the current scores for all the neighbors. Specifically, the new scores are</p>
<p><span class="math display">\[
x_i^+ = \sum_{j\text{ adjacent to }i} x_j = \sum_{j=1}^n A_{ij} x_j,\quad i=1,\ldots,n,
\]</span></p>
<p>where <span class="math inline">\(A_{ij}\)</span> are entries of the adjacency matrix. Once we have updated the scores, we can repeat the process to update them again, and so on. If the scores were to converge, in the sense that <span class="math inline">\(x_i^+\)</span> approaches <span class="math inline">\(x_i\)</span>, then we would have a solution of the equation</p>
<p><span class="math display">\[
x_i \stackrel{?}{=} \sum_{j=1}^n A_{ij} x_j, \quad i=1,\ldots,n.
\]</span></p>
<p>In fact, since the sums are all inner products across rows of <span class="math inline">\(\bfA\)</span>, this is simply</p>
<p><span class="math display">\[
\bfx \stackrel{?}{=} \bfA \bfx.
\]</span></p>
<p>Except for <span class="math inline">\(\bfx\)</span> equal to the zero vector, this equation does not have a solution in general. However, if we relax it just a bit, we get somewhere important. Instead of equality, let’s look for <em>proportionality</em>, i.e.,</p>
<p><span class="math display">\[
\lambda \bfx = \bfA \bfx
\]</span></p>
<p>for a number <span class="math inline">\(\lambda\)</span>. This is an <strong>eigenvalue equation</strong>, one of the fundamental problems in linear algebra.</p>
<div class="{prf:example}">
<p>:label: example-centrality-eigenvector Consider the complete graph <span class="math inline">\(K_3\)</span>, which is just a triangle. Its adjacency matrix is</p>
<p><span class="math display">\[
\bfA = \begin{bmatrix}
0 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 0
\end{bmatrix}.
\]</span></p>
<p>We should hope that all three vertices are ranked equally. In fact, if we define <span class="math inline">\(\bfx=\tfrac{1}{3}[1,1,1]\)</span>, then</p>
<p><span class="math display">\[
\bfA \bfx = \bigl[\tfrac{2}{3},\tfrac{2}{3},\tfrac{2}{3} \bigr] = 2 \bfx,
\]</span></p>
<p>so that <span class="math inline">\(\lambda=2\)</span> is an eigenvalue to go with eigenvector <span class="math inline">\(\bfx\)</span>. Note that any (nonzero) multiple of <span class="math inline">\(\bfx\)</span> would work just as well:</p>
<p><span class="math display">\[
\bfA (c \bfx) =  \bigl[\tfrac{2}{3}c,\tfrac{2}{3}c,\tfrac{2}{3}c \bigr] = 2 (c\bfx),
\]</span></p>
<p>so that <span class="math inline">\(c\bfx\)</span> is also an eigenvector. All that the eigenvector gives us, then, is <em>relative</em> centrality of the nodes, though it would be natural to normalize it so that its elements sum to 1.</p>
</div>
<p>Every <span class="math inline">\(n\times n\)</span> matrix has at least one nonzero solution to the eigenvalue equation, although complex numbers might be involved. For an adjacency matrix, the <em>Perron–Frobenius theorem</em> guarantees a real solution for some <span class="math inline">\(\lambda &gt; 0\)</span> and for which the <span class="math inline">\(x_i\)</span> all have the same sign. That last property allows us to interpret the <span class="math inline">\(x_i\)</span> as relative importance or centrality of the nodes. This is called <strong>eigenvector centrality</strong>.</p>
<p>NetworkX has two functions for computing eigenvector centrality. Here we use the one that calls on numpy to solve the eigenvalue problem. As with betweenness centrality, the return value is a dictionary with nodes as the keys.</p>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>centrality[<span class="st">"eigen"</span>] <span class="op">=</span> pd.Series(nx.eigenvector_centrality_numpy(G),index<span class="op">=</span>G.nodes)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>sns.displot(data<span class="op">=</span>centrality,x<span class="op">=</span><span class="st">"eigen"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-76-output-1.png" width="469" height="468"></p>
</div>
</div>
<p>You can see above that eigenvector centrality distinguishes a small number of nodes in our example.</p>
</section>
<section id="comparison" class="level3" data-number="7.5.3">
<h3 data-number="7.5.3" class="anchored" data-anchor-id="comparison"><span class="header-section-number">7.5.3</span> Comparison</h3>
<p>We can verify using correlation coefficients that while the three centrality measures are related, they are far from redundant:</p>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>centrality.corr()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<div>


<table class="dataframe table table-sm table-striped" data-border="1">
<thead>
<tr class="header">
<th></th>
<th>degree</th>
<th>between</th>
<th>eigen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th>degree</th>
<td>1.000000</td>
<td>0.630732</td>
<td>0.601884</td>
</tr>
<tr class="even">
<th>between</th>
<td>0.630732</td>
<td>1.000000</td>
<td>0.736732</td>
</tr>
<tr class="odd">
<th>eigen</th>
<td>0.601884</td>
<td>0.736732</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Here is how betweenness ranks the centrality of the nodes:</p>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>centrality.sort_values(by<span class="op">=</span><span class="st">"between"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<div>


<table class="dataframe table table-sm table-striped" data-border="1">
<thead>
<tr class="header">
<th></th>
<th>degree</th>
<th>between</th>
<th>eigen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th>42</th>
<td>0.050847</td>
<td>0.595850</td>
<td>0.405831</td>
</tr>
<tr class="even">
<th>23</th>
<td>0.050847</td>
<td>0.576856</td>
<td>0.458056</td>
</tr>
<tr class="odd">
<th>41</th>
<td>0.033898</td>
<td>0.385739</td>
<td>0.232910</td>
</tr>
<tr class="even">
<th>40</th>
<td>0.033898</td>
<td>0.368206</td>
<td>0.133669</td>
</tr>
<tr class="odd">
<th>51</th>
<td>0.050847</td>
<td>0.363822</td>
<td>0.392303</td>
</tr>
<tr class="even">
<th>39</th>
<td>0.033898</td>
<td>0.349503</td>
<td>0.076714</td>
</tr>
<tr class="odd">
<th>38</th>
<td>0.033898</td>
<td>0.329632</td>
<td>0.044027</td>
</tr>
<tr class="even">
<th>22</th>
<td>0.033898</td>
<td>0.329632</td>
<td>0.262883</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>As you can see, the top two are quite clear, and a drawing of the graph supports the case that they are central:</p>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>nx.draw(G, node_size<span class="op">=</span><span class="dv">500</span><span class="op">*</span>centrality[<span class="st">"between"</span>], <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-79-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>A weakness, though, is that there is are many secondary nodes whose values taper off only slowly as we enter the remote branches.</p>
<p>Here is a ranking according to eigenvector centrality:</p>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>centrality.sort_values(by<span class="op">=</span><span class="st">"eigen"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<div>


<table class="dataframe table table-sm table-striped" data-border="1">
<thead>
<tr class="header">
<th></th>
<th>degree</th>
<th>between</th>
<th>eigen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th>23</th>
<td>0.050847</td>
<td>0.576856</td>
<td>0.458056</td>
</tr>
<tr class="even">
<th>42</th>
<td>0.050847</td>
<td>0.595850</td>
<td>0.405831</td>
</tr>
<tr class="odd">
<th>51</th>
<td>0.050847</td>
<td>0.363822</td>
<td>0.392303</td>
</tr>
<tr class="even">
<th>22</th>
<td>0.033898</td>
<td>0.329632</td>
<td>0.262883</td>
</tr>
<tr class="odd">
<th>4</th>
<td>0.033898</td>
<td>0.311806</td>
<td>0.249077</td>
</tr>
<tr class="even">
<th>41</th>
<td>0.033898</td>
<td>0.385739</td>
<td>0.232910</td>
</tr>
<tr class="odd">
<th>52</th>
<td>0.033898</td>
<td>0.134717</td>
<td>0.225527</td>
</tr>
<tr class="even">
<th>50</th>
<td>0.033898</td>
<td>0.212741</td>
<td>0.225125</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This ranking has a clear top choice, followed by two that are nearly identical.</p>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>nx.draw(G, node_size<span class="op">=</span><span class="dv">800</span><span class="op">*</span>centrality[<span class="st">"eigen"</span>], <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-81-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>Eigenvector centrality identifies a more compact and distinct center. Of course, these observations are all made for a single network, so be careful not to over-generalize!</p>
</section>
<section id="power-law-example" class="level3" data-number="7.5.4">
<h3 data-number="7.5.4" class="anchored" data-anchor-id="power-law-example"><span class="header-section-number">7.5.4</span> Power-law example</h3>
<p>Let’s take a look at centrality measures for a power-law graph of the same size. By construction, a BA graph has a hub-and-spoke structure.</p>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.barabasi_albert_graph(<span class="dv">60</span>, <span class="dv">1</span>, seed<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>style[<span class="st">"pos"</span>] <span class="op">=</span> nx.spring_layout(G, seed<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>nx.draw(G, <span class="op">**</span>style, node_size<span class="op">=</span><span class="dv">120</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-82-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>Degree centrality certainly notices the gregarious node 0:</p>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>centrality <span class="op">=</span> pd.DataFrame( {<span class="st">"degree"</span>:nx.degree_centrality(G)}, index<span class="op">=</span>G.nodes )</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>nx.draw(G, node_size<span class="op">=</span><span class="dv">1000</span><span class="op">*</span>centrality[<span class="st">"degree"</span>], <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-83-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>However, as you see above, the secondary hubs do not stand out much. Betweenness centrality highlights them quite nicely here:</p>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>centrality[<span class="st">"between"</span>] <span class="op">=</span> pd.Series(nx.betweenness_centrality(G))</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>nx.draw(G, node_size<span class="op">=</span><span class="dv">600</span><span class="op">*</span>centrality[<span class="st">"between"</span>], <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-84-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>On the other hand, eigenvector centrality puts a lot of emphasis on the friends of node 0, even the ones that are dead ends, at the expense of the secondary hubs:</p>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>centrality[<span class="st">"eigen"</span>] <span class="op">=</span> pd.Series( nx.eigenvector_centrality_numpy(G) )</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>nx.draw(G, node_size<span class="op">=</span><span class="dv">600</span><span class="op">*</span>centrality[<span class="st">"eigen"</span>], <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-85-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>This undesirable aspect of eigenvector centrality can be fixed through an extra normalization by the node degree, so that the hub node divides its “attention” into smaller parts. Such thinking leads to the <em>PageRank</em> algorithm, which is what put Google on the map for web searches.</p>
</section>
<section id="friendship-paradox" class="level3" data-number="7.5.5">
<h3 data-number="7.5.5" class="anchored" data-anchor-id="friendship-paradox"><span class="header-section-number">7.5.5</span> Friendship paradox</h3>
<p>A surprising fact about social networks is that on average, your friends have more friends than you do, a fact that is called the <strong>friendship paradox</strong>. Let <span class="math inline">\(\mathbf{d}\)</span> be an <span class="math inline">\(n\)</span>-vector whose components are the degrees of the nodes in the network. On average, the number of “friends” (i.e., adjacent nodes) is the average degree, which is equal to</p>
<p><span class="math display">\[
\frac{\onenorm{\mathbf{d}}}{n}.
\]</span></p>
<p>Now imagine that we create a list as follows: for each node <span class="math inline">\(i\)</span>, add to the list the number of friends of each of <span class="math inline">\(i\)</span>’s friends. The mean value of this list is the average number of “friends of friends.”</p>
<p>For example, consider the following graph:</p>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> nx.lollipop_graph(<span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>nx.draw(L, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">"lightblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-86-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>The average degree is <span class="math inline">\((3+3+3+4+1)/5=14/5\)</span>. Here are the entries in our friends-of-friends list contributed by each node:</p>
<ul>
<li>Node 0: 3 (from node 1), 3 (from node 2), 4 (from node 3)</li>
<li>Node 1: 3 (from node 0), 3 (from node 2), 4 (from node 3)</li>
<li>Node 2: 3 (from node 0), 3 (from node 1), 4 (from node 3)</li>
<li>Node 3: 3 (from node 0), 3 (from node 1), 3 (from node 2), 1 (from node 4)</li>
<li>Node 4: 4 (from node 3)</li>
</ul>
<p>The average value of this list, i.e., the average number of friends’ friends, is <span class="math inline">\(44/14=3.143\)</span>, which is indeed larger than the average degree.</p>
<p>There is an easy way to calculate this value in general. Node <span class="math inline">\(i\)</span> contributes <span class="math inline">\(d_i\)</span> terms to the list, so the total number of terms is <span class="math inline">\(\onenorm{\mathbf{d}}\)</span>. We observe that node <span class="math inline">\(i\)</span> appears <span class="math inline">\(d_i\)</span> times in the list, each time contributing the value <span class="math inline">\(d_i\)</span>, so the sum of the entire list must be</p>
<p><span class="math display">\[
\sum_{i=1}^n d_i^2 = \twonorm{\mathbf{d}}^2 = \mathbf{d}^T \mathbf{d}.
\]</span></p>
<p>Hence the mathematical statement of the friendship paradox is</p>
<p><span id="eq-networks-friendship-paradox"><span class="math display">\[
\frac{\onenorm{\mathbf{d}}}{n} \le \frac{\mathbf{d}^T \mathbf{d}}{\onenorm{\mathbf{d}}}.
\tag{7.2}\]</span></span></p>
<p>You are asked to prove this inequality in the exercises. Here is a verification for the BA graph above:</p>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> G.number_of_nodes()</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> pd.Series(<span class="bu">dict</span>(G.degree), index<span class="op">=</span>G.nodes)</span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>dbar <span class="op">=</span> d.mean()</span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>dbar_friends <span class="op">=</span> np.dot(d,d) <span class="op">/</span> d.<span class="bu">sum</span>()</span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-6"><a href="#cb138-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dbar, <span class="st">"is less than"</span>, dbar_friends)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.9666666666666666 is less than 4.389830508474576</code></pre>
</div>
</div>
<p>The friendship paradox generalizes to eigenvector centrality: the average centrality of all nodes is less than the average of the centrality of all nodes’ friends. The mathematical statement is <span id="eq-networks-eigen-paradox"><span class="math display">\[
\frac{\onenorm{\mathbf{x}}}{n} \le \frac{\mathbf{x}^T \mathbf{d}}{\onenorm{\mathbf{d}}},
\tag{7.3}\]</span></span> where <span class="math inline">\(\bfx\)</span> is the eigenvector defining centrality of the nodes.</p>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> centrality[<span class="st">"eigen"</span>]</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>xbar <span class="op">=</span> x.mean()</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>xbar_friends <span class="op">=</span> np.dot(x,d) <span class="op">/</span> <span class="bu">sum</span>(d)</span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xbar, <span class="st">"is less than"</span>, xbar_friends)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.07583936265862018 is less than 0.15936510918420194</code></pre>
</div>
</div>
<p>In fact, the friendship paradox inequality for any vector <span class="math inline">\(\bfx\)</span> is equivalent to <span class="math inline">\(\bfx\)</span> having nonnegative correlation with the degree vector.</p>
</section>
</section>
<section id="communities" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="communities"><span class="header-section-number">7.6</span> Communities</h2>
<p>In applications, one may want to identify <em>communities</em> within a network. There are many ways to define this concept precisely. We will choose a <strong>random-walk</strong> model.</p>
<p>Imagine that a bunny sits on node <span class="math inline">\(i\)</span>. In one second, the bunny hops to one of <span class="math inline">\(i\)</span>’s neighbors, chosen randomly. In the next second, the bunny hops to another node chosen randomly from the neighbors of the one it is sitting on, etc. This is a random walk on the nodes of the graph.</p>
<p>Now imagine that we place another bunny on node <span class="math inline">\(i\)</span> and track its path as it hops around the graph. Then we place another bunny, etc., so that we have an ensemble of walks. We can now reason about the <em>probability</em> of the location of the walk after any number of hops. Initially, the probability of node <span class="math inline">\(i\)</span> is 100%. If <span class="math inline">\(i\)</span> has <span class="math inline">\(m\)</span> neighbors, then each of them will have probability <span class="math inline">\(1/m\)</span> after one hop, and all the other nodes (including <span class="math inline">\(i\)</span> itself) have zero probability.</p>
<p>Let’s keep track of the probabilities for this simple wheel graph:</p>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.wheel_graph(<span class="dv">5</span>)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>nx.draw(G, node_size<span class="op">=</span><span class="dv">300</span>, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">"yellow"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-89-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>We start at node 4. This corresponds to the probability vector</p>
<p><span class="math display">\[
\bfp = [0,0,0,0,1].
\]</span></p>
<p>On the first hop, we are equally likely to visit each of the nodes 0, 1, or 3. This implies the probability distribution</p>
<p><span class="math display">\[
\mathbf{q} = \left[\tfrac{1}{3},\tfrac{1}{3},0,\tfrac{1}{3},0\right].
\]</span></p>
<p>Let’s now find the probability of standing on node 0 after the next hop. The two possible histories are 4-1-0 and 4-3-0, with total probability</p>
<p><span class="math display">\[
\underbrace{\frac{1}{3}}_{\text{to 1}} \cdot \underbrace{\frac{1}{3}}_{\text{to 0}} + \underbrace{\frac{1}{3}}_{\text{to 3}} \cdot \underbrace{\frac{1}{3}}_{\text{to 0}} = \frac{2}{9}.
\]</span></p>
<p>What about node 2 after two hops? The viable paths are 4-0-2, 4-1-2, and 4-3-2. Keeping in mind that node 0 has 4 neighbors, we get</p>
<p><span class="math display">\[
\underbrace{\frac{1}{3}}_{\text{to 0}} \cdot \underbrace{\frac{1}{4}}_{\text{to 2}} + \underbrace{\frac{1}{3}}_{\text{to 1}} \cdot \underbrace{\frac{1}{3}}_{\text{to 2}} + \underbrace{\frac{1}{3}}_{\text{to 3}} \cdot \underbrace{\frac{1}{3}}_{\text{to 2}}= \frac{11}{36}.
\]</span></p>
<p>This quantity is actually an inner product between the vector <span class="math inline">\(\mathbf{q}\)</span> (probabilities of the prior location) and</p>
<p><span class="math display">\[
\bfw_2 = \left[ \tfrac{1}{4},\, \tfrac{1}{3},\, 0,\, \tfrac{1}{3},\, 0 \right],
\]</span></p>
<p>which encodes the chance of hopping directly to node 2 from anywhere. In fact, the entire next vector of probabilities is just</p>
<p><span class="math display">\[
\bigl[ \bfw_1^T \mathbf{q},\, \bfw_2^T \mathbf{q},\, \bfw_3^T \mathbf{q},\, \bfw_4^T \mathbf{q},\, \bfw_5^T \mathbf{q} \bigr] = \bfW \mathbf{q},
\]</span></p>
<p>where <span class="math inline">\(\bfW\)</span> is the <span class="math inline">\(n\times n\)</span> matrix whose rows are <span class="math inline">\(\bfw_1,\bfw_2,\ldots.\)</span> In terms of matrix-vector multiplications, we have the easy statement that the probability vectors after each hop are</p>
<p><span class="math display">\[
\bfp, \bfW\bfp, \bfW(\bfW\bfp), \ldots.
\]</span></p>
<p>Explicitly, the matrix <span class="math inline">\(\bfW\)</span> is</p>
<p><span class="math display">\[
\bfW = \begin{bmatrix}
0 &amp; \tfrac{1}{3}  &amp; \tfrac{1}{3}  &amp; \tfrac{1}{3}  &amp; \tfrac{1}{3} \\
\tfrac{1}{4} &amp; 0 &amp; \tfrac{1}{3}  &amp; 0  &amp; \tfrac{1}{3} \\
\tfrac{1}{4} &amp; \tfrac{1}{3} &amp; 0 &amp; \tfrac{1}{3} &amp; 0 \\
\tfrac{1}{4} &amp; 0 &amp; \tfrac{1}{3} &amp; 0 &amp; \tfrac{1}{3} \\
\tfrac{1}{4} &amp; \tfrac{1}{3} &amp; 0 &amp; \tfrac{1}{3} &amp; 0
\end{bmatrix}.
\]</span></p>
<p>This has a lot of resemblance to the adjacency matrix</p>
<p><span class="math display">\[
\bfA = \begin{bmatrix}
0 &amp; 1  &amp; 1  &amp; 1  &amp; 1 \\
1 &amp; 0 &amp; 1 &amp; 0  &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix}.
\]</span></p>
<p>The only difference is that each column has to be normalized by the number of options outgoing at that node, i.e., the degree of the node. Thus,</p>
<p><span class="math display">\[
W_{ij} = \frac{1}{\operatorname{deg}(j)}\,A_{ij}.
\]</span></p>
<section id="simulating-the-random-walk" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="simulating-the-random-walk"><span class="header-section-number">7.6.1</span> Simulating the random walk</h3>
<p>Let’s do a simulation for a more interesting graph:</p>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>WS <span class="op">=</span> nx.watts_strogatz_graph(<span class="dv">40</span>, <span class="dv">4</span>, <span class="fl">0.04</span>, seed<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(WS, k<span class="op">=</span><span class="fl">0.25</span>, seed<span class="op">=</span><span class="dv">1</span>, iterations<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>style <span class="op">=</span> <span class="bu">dict</span>(pos<span class="op">=</span>pos, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">"pink"</span>, edge_color<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a>nx.draw(WS, node_size<span class="op">=</span><span class="dv">240</span>, <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-90-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>First, we construct the random-walk matrix <span class="math inline">\(\bfW\)</span>.</p>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> WS.number_of_nodes()</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> nx.adjacency_matrix(WS).astype(<span class="bu">float</span>)</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>degree <span class="op">=</span> [ WS.degree[i] <span class="cf">for</span> i <span class="kw">in</span> WS.nodes ] </span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> A.copy()</span>
<span id="cb144-6"><a href="#cb144-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb144-7"><a href="#cb144-7" aria-hidden="true" tabindex="-1"></a>    W[:,j] <span class="op">/=</span> degree[j]</span>
<span id="cb144-8"><a href="#cb144-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-9"><a href="#cb144-9" aria-hidden="true" tabindex="-1"></a>sns.heatmap(W.toarray()).set_aspect(<span class="dv">1</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-91-output-1.png" width="495" height="411"></p>
</div>
</div>
<p>We set up a probability vector to start at node 0, and then use <code>W.dot</code> to compute the first hop. The result is to end up at 5 other nodes with equal probability:</p>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>init <span class="op">=</span> <span class="dv">33</span></span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> np.zeros(n)</span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a>p[init] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> W.dot(p)</span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a>sz <span class="op">=</span> <span class="dv">3000</span><span class="op">*</span>p</span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Total probability after 1 hop:"</span>, p.<span class="bu">sum</span>() )</span>
<span id="cb145-7"><a href="#cb145-7" aria-hidden="true" tabindex="-1"></a>nx.draw(WS, node_size<span class="op">=</span>sz, <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total probability after 1 hop: 1.0</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-92-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>After the next hop, there will again be a substantial probability of being at node 33. But we could also be at some second-generation nodes as well.</p>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> W.dot(p)</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Total probability after 2 hops:"</span>, p.<span class="bu">sum</span>() )</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>nx.draw(WS, node_size<span class="op">=</span><span class="dv">3000</span><span class="op">*</span>p, <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total probability after 2 hops: 1.0</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-93-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>We’ll take 3 more hops. That lets us penetrate a little into the distant nodes.</p>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> W.dot(p)</span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">"Total probability after 5 hops:"</span>, p.<span class="bu">sum</span>() )</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a>nx.draw(WS, node_size<span class="op">=</span><span class="dv">3000</span><span class="op">*</span>p, <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total probability after 5 hops: 1.0</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-94-output-2.png" width="691" height="499"></p>
</div>
</div>
<p>In the long run, the probabilities even out, as long as the graph is connected.</p>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> W.dot(p)</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>nx.draw(WS, node_size<span class="op">=</span><span class="dv">3000</span><span class="op">*</span>p, <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-95-output-1.png" width="691" height="499"></p>
</div>
</div>
</section>
<section id="label-propagation" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="label-propagation"><span class="header-section-number">7.6.2</span> Label propagation</h3>
<p>The random walk brings us to a type of algorithm known as <strong>label propagation</strong>. We start off by “labelling” one or several nodes whose community we want to identify. This is equivalent to initializing the probability vector <span class="math inline">\(\bfp\)</span>. Then, we take a running total over the entire history of the random walk:</p>
<p><span class="math display">\[
\hat{\bfx} = \lambda \bfp_1  + \lambda^2 \bfp_2 +  \lambda^3 \bfp_3 + \cdots,
\]</span></p>
<p>where <span class="math inline">\(0 &lt; \lambda &lt; 1\)</span> is a damping parameter, and</p>
<p><span class="math display">\[
\bfp_1 = \bfW \bfp, \, \bfp_2 = \bfW \bfp_1, \, \bfp_3 = \bfW \bfp_2,\, \ldots.
\]</span></p>
<!-- 
. It's irresistible (and legit linear algebra) to write $\bfW (\bfW \bfp) = \bfW^2\bfp$ and so on for future iterations. Hence,

$$
\hat{\bfx} = \sum_{k=1}^\infty \lambda^k \bfW^k \bfp.
$$ 
-->
<p>In practice, we terminate the sum once <span class="math inline">\(\lambda^k\)</span> is sufficiently small. The resulting <span class="math inline">\(\hat{\bfx}\)</span> can be normalized to a probability distribution,</p>
<p><span class="math display">\[
\bfx = \frac{\hat{\bfx}}{\norm{\hat{\bfx}}_1}.
\]</span></p>
<p>The value <span class="math inline">\(x_i\)</span> can be interpreted as the probability of membership in the community.</p>
<p>Let’s try looking for a community of node 0 in the WS graph above.</p>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> np.zeros(n)</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>p[init] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="fl">0.8</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will compute <span class="math inline">\(\bfx\)</span> by accumulating terms in a loop. Note that there is no need to keep track of the entire history of random-walk probabilities; we just use one generation at a time.</p>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.zeros(n)</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>mult <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> W.dot(p)</span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a>    mult <span class="op">*=</span> lam</span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a>    x <span class="op">+=</span> mult<span class="op">*</span>p</span>
<span id="cb153-7"><a href="#cb153-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-8"><a href="#cb153-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">/=</span> np.<span class="bu">sum</span>(x)  <span class="co"># normalize to probability distribution</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The probabilities tend to be distributed logarithmically:</p>
<p>In the following rendering, any node <span class="math inline">\(i\)</span> with a value of <span class="math inline">\(x_i &lt; 10^{-2}\)</span> gets a node size of 0. (You can ignore the warning below. It happens because we have negative node sizes.)</p>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>x[x<span class="op">&lt;</span><span class="fl">0.01</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>style[<span class="st">"node_color"</span>] <span class="op">=</span> <span class="st">"lightblue"</span></span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>nx.draw(WS, node_size<span class="op">=</span><span class="dv">4000</span><span class="op">*</span>x, <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-98-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>The parameter <span class="math inline">\(\lambda\)</span> controls how quickly the random-walk process is faded out. A smaller value puts more weight on the early iterations, generally localizing the community more strictly.</p>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> np.zeros(n)</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>p[init] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.zeros(n)</span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a>mult <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb155-7"><a href="#cb155-7" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> W.dot(p)</span>
<span id="cb155-8"><a href="#cb155-8" aria-hidden="true" tabindex="-1"></a>    mult <span class="op">*=</span> lam</span>
<span id="cb155-9"><a href="#cb155-9" aria-hidden="true" tabindex="-1"></a>    x <span class="op">+=</span> mult<span class="op">*</span>p</span>
<span id="cb155-10"><a href="#cb155-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-11"><a href="#cb155-11" aria-hidden="true" tabindex="-1"></a>x <span class="op">/=</span> np.<span class="bu">sum</span>(x)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>x[x<span class="op">&lt;</span><span class="fl">0.01</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>nx.draw(WS, node_size<span class="op">=</span><span class="dv">4000</span><span class="op">*</span>x, <span class="op">**</span>style)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-100-output-1.png" width="691" height="499"></p>
</div>
</div>
<p>In practice, we could define a threshold cutoff on the probabilities, or set a community size and take the highest-ranking nodes. Then a new node could be selected and a community identified for it in the subgraph without the first community, etc.</p>
<p>A more sophisticated version of the label propagation algorithm (and many other community detection methods) is offered in a special module.</p>
<div class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> networkx.algorithms.community <span class="im">import</span> label_propagation_communities</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>comm <span class="op">=</span> label_propagation_communities(WS)</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>[ <span class="bu">print</span>(c) <span class="cf">for</span> c <span class="kw">in</span> comm ]<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{0, 1, 2, 3, 39}
{4, 5, 6, 7, 8, 29, 30, 31}
{9, 10, 11}
{12, 13, 14, 15}
{16, 17, 18, 19, 20}
{32, 33, 34, 35, 21}
{22, 23, 24, 25, 26, 27, 28}
{36, 37, 38}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> np.array( [<span class="st">"lightblue"</span>,<span class="st">"pink"</span>,<span class="st">"yellow"</span>,<span class="st">"lightgreen"</span>,<span class="st">"purple"</span>,<span class="st">"orange"</span>,<span class="st">"red"</span>,<span class="st">"lightgray"</span>] )</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>color_index <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span>n</span>
<span id="cb159-3"><a href="#cb159-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,S <span class="kw">in</span> <span class="bu">enumerate</span>(comm):</span>
<span id="cb159-4"><a href="#cb159-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> S:</span>
<span id="cb159-5"><a href="#cb159-5" aria-hidden="true" tabindex="-1"></a>        color_index[k] <span class="op">=</span> i</span>
<span id="cb159-6"><a href="#cb159-6" aria-hidden="true" tabindex="-1"></a>nx.draw( WS, node_size<span class="op">=</span><span class="dv">100</span>, pos<span class="op">=</span>pos, node_color<span class="op">=</span>color[color_index] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="networks_files/figure-html/cell-102-output-1.png" width="691" height="499"></p>
</div>
</div>
</section>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<div id="exr-networks-basic" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.1 </strong></span>For each graph, give the number of nodes, the number of edges, and the average degree.</p>
<p><strong>(a)</strong> The complete graph <span class="math inline">\(K_6\)</span>.</p>
<p><strong>(b)</strong> <img src="_media/nws.png" title="NWS graph" class="img-fluid" width="380"></p>
<p><strong>(c)</strong> <img src="_media/ladder.png" title="Ladder graph" class="img-fluid" width="380"></p>
</div>
<div id="exr-networks-adjmat" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.2 </strong></span>Give the adjacency matrix for the graphs in <a href="#exr-networks-basic">Exercise&nbsp;<span>7.1</span></a> (parts (a) and (b) only).</p>
</div>
<div id="exr-networks-ego" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.3 </strong></span>For the graph below, draw the ego graph of <strong>(a)</strong> node 4 and <strong>(b)</strong> node 8.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="_media/ba.png" title="BA graph" class="img-fluid figure-img" width="380"></p>
</figure>
</div>
</div>
<div id="exr-networks-erprob" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.4 </strong></span>To construct an Erdős-Rényi graph on 25 nodes with expected average degree 8, what should the edge inclusion probability <span class="math inline">\(p\)</span> be?</p>
</div>
<div id="exr-networks-diam" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.5 </strong></span>Find the diameters of the graphs in <a href="#exr-networks-basic">Exercise&nbsp;<span>7.1</span></a>.</p>
</div>
<div id="exr-networks-degree-vector" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.6 </strong></span>Suppose that <span class="math inline">\(\bfA\)</span> is the adjacency matrix of an undirected graph on <span class="math inline">\(n\)</span> nodes. Let <span class="math inline">\(\boldsymbol{1}\)</span> be the <span class="math inline">\(n\)</span>-vector whose components all equal 1, and let <span class="math display">\[
\mathbf{d} = \bfA \boldsymbol{1}.
\]</span> Explain why <span class="math inline">\(\mathbf{d}\)</span> is the vector whose components are the degrees of the nodes.</p>
</div>
<div id="exr-networks-centrality" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.7 </strong></span>Find <strong>(a)</strong> the clustering coefficient and <strong>(b)</strong> the betweenness centrality for each node in the following graph:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="_media/lolly.png" title="lollipop graph" class="img-fluid figure-img" width="380"></p>
</figure>
</div>
</div>
<div id="exr-networks-centrality-star" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.8 </strong></span>A star graph with <span class="math inline">\(n\)</span> nodes and <span class="math inline">\(n-1\)</span> edges has a central node that has an edge to each other node. In terms of <span class="math inline">\(n\)</span>, find <strong>(a)</strong> the clustering coefficient and <strong>(b)</strong> the betweenness centrality of the central node of the star graph.</p>
</div>
<div id="exr-networks-ring-lattice" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.9 </strong></span>The Watts–Strogatz construction starts with a <em>ring lattice</em> in which the nodes are arranged in a circle and each is connected to its <span class="math inline">\(k\)</span> nearest neighbors (i.e., <span class="math inline">\(k/2\)</span> on each side). Show that the clustering coefficient of an arbitrary node in the ring lattice is <span class="math display">\[
\frac{3(k-2)}{4(k-1)}.
\]</span></p>
<p>(Hint: Count up all the edges between the neighbors on one side of the node of interest, then all the edges between neighbors on the other side, and finally, the edges going from a neighbor on one side to a neighbor on the other side. It might be easier to work with <span class="math inline">\(m=k/2\)</span> and then eliminate <span class="math inline">\(m\)</span> at the end.)</p>
</div>
<div id="exr-networks-centrality-complete" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.10 </strong></span>Recall that the complete graph <span class="math inline">\(K_n\)</span> contains every possible edge on <span class="math inline">\(n\)</span> nodes. Prove that the vector <span class="math inline">\(\bfx=[1,1,\ldots,1]\)</span> is an eigenvector of the adjacency matrix of <span class="math inline">\(K_n\)</span>. (Therefore, the eigenvector centrality is uniform over the nodes.)</p>
</div>
<div id="exr-networks-star-eigen" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.11 </strong></span>Prove that for the star graph on <span class="math inline">\(n\)</span> nodes as described in Exercise 8, the vector <span class="math display">\[
\bfx = \bigl[ \sqrt{n-1},1,1,\ldots,1 \bigr]
\]</span> is an eigenvector of the adjacency matrix, where the central node corresponds to the first element of the vector.</p>
</div>
<div id="exr-networks-friendship" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.12 </strong></span>Prove the friendship paradox, i.e., inequality <a href="#eq-networks-friendship-paradox">Equation&nbsp;<span>7.2</span></a>. (Hint: Start with <a href="clustering.html#eq-cluster-angle">Equation&nbsp;<span>6.1</span></a> using <span class="math inline">\(\bfu=\mathbf{d}\)</span> and <span class="math inline">\(\bfv\)</span> equal to a vector of all ones. Convert from equality to inequality to get rid of the angle <span class="math inline">\(\theta\)</span>. Simplify the inner product, square both sides, and show that it can be rearranged into <a href="#eq-networks-friendship-paradox">Equation&nbsp;<span>7.2</span></a>.)</p>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./clustering.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Clustering</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Data Science 1
  </li>  
</ul>
    </div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Toby Driscoll
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>